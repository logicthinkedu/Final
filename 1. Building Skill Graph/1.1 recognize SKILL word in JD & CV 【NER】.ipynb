{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                  *  /home/lothar/anaconda3\r\n",
      "CRF_tf2                  /home/lothar/anaconda3/envs/CRF_tf2\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/lothar/anaconda3:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "absl-py                   0.9.0                    pypi_0    pypi\r\n",
      "alabaster                 0.7.12                   py37_0  \r\n",
      "anaconda                  2020.02                  py37_0  \r\n",
      "anaconda-client           1.7.2                    py37_0  \r\n",
      "anaconda-navigator        1.9.12                   py37_0  \r\n",
      "anaconda-project          0.8.4                      py_0  \r\n",
      "argh                      0.26.2                   py37_0  \r\n",
      "asn1crypto                1.3.0                    py37_0  \r\n",
      "astor                     0.8.1                    pypi_0    pypi\r\n",
      "astroid                   2.3.3                    py37_0  \r\n",
      "astropy                   4.0              py37h7b6447c_0  \r\n",
      "astunparse                1.6.3                    pypi_0    pypi\r\n",
      "atomicwrites              1.3.0                    py37_1  \r\n",
      "attrs                     19.3.0                     py_0  \r\n",
      "autopep8                  1.4.4                      py_0  \r\n",
      "babel                     2.8.0                      py_0  \r\n",
      "backcall                  0.1.0                    py37_0  \r\n",
      "backports                 1.0                        py_2  \r\n",
      "backports.functools_lru_cache 1.6.1                      py_0  \r\n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \r\n",
      "backports.tempfile        1.0                        py_1  \r\n",
      "backports.weakref         1.0.post1                  py_1  \r\n",
      "beautifulsoup4            4.8.2                    py37_0  \r\n",
      "bitarray                  1.2.1            py37h7b6447c_0  \r\n",
      "bkcharts                  0.2                      py37_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    3.1.0                    py37_0  \r\n",
      "blessings                 1.7                      pypi_0    pypi\r\n",
      "blis                      0.4.1                    pypi_0    pypi\r\n",
      "blosc                     1.16.3               hd408876_0  \r\n",
      "bokeh                     1.4.0                    py37_0  \r\n",
      "boto                      2.49.0                   py37_0  \r\n",
      "boto3                     1.14.48                  pypi_0    pypi\r\n",
      "botocore                  1.17.48                  pypi_0    pypi\r\n",
      "bottleneck                1.3.2            py37heb32a55_0  \r\n",
      "bzip2                     1.0.8                h7b6447c_0  \r\n",
      "ca-certificates           2020.1.1                      0  \r\n",
      "cachetools                4.1.1                    pypi_0    pypi\r\n",
      "cairo                     1.14.12              h8948797_3  \r\n",
      "catalogue                 1.0.0                    pypi_0    pypi\r\n",
      "certifi                   2019.11.28               py37_0  \r\n",
      "cffi                      1.14.0           py37h2e261b9_0  \r\n",
      "chardet                   3.0.4                 py37_1003  \r\n",
      "click                     7.0                      py37_0  \r\n",
      "cloudpickle               1.3.0                      py_0  \r\n",
      "clyent                    1.2.2                    py37_1  \r\n",
      "colorama                  0.4.3                      py_0  \r\n",
      "conda                     4.8.2                    py37_0  \r\n",
      "conda-build               3.18.11                  py37_0  \r\n",
      "conda-env                 2.6.0                         1  \r\n",
      "conda-package-handling    1.6.0            py37h7b6447c_0  \r\n",
      "conda-verify              3.4.2                      py_1  \r\n",
      "contextlib2               0.6.0.post1                py_0  \r\n",
      "cryptography              2.8              py37h1ba5d50_0  \r\n",
      "curl                      7.68.0               hbc83047_0  \r\n",
      "cycler                    0.10.0                   py37_0  \r\n",
      "cymem                     2.0.3                    pypi_0    pypi\r\n",
      "cython                    0.29.15          py37he6710b0_0  \r\n",
      "cytoolz                   0.10.1           py37h7b6447c_0  \r\n",
      "dask                      2.11.0                     py_0  \r\n",
      "dask-core                 2.11.0                     py_0  \r\n",
      "databricks-cli            0.11.0                   pypi_0    pypi\r\n",
      "dbus                      1.13.12              h746ee38_0  \r\n",
      "decorator                 4.4.1                      py_0  \r\n",
      "defusedxml                0.6.0                      py_0  \r\n",
      "diff-match-patch          20181111                   py_0  \r\n",
      "distributed               2.11.0                   py37_0  \r\n",
      "docutils                  0.15.2                   pypi_0    pypi\r\n",
      "en-core-web-sm            2.3.1                    pypi_0    pypi\r\n",
      "entrypoints               0.3                      py37_0  \r\n",
      "et_xmlfile                1.0.1                    py37_0  \r\n",
      "expat                     2.2.6                he6710b0_0  \r\n",
      "fastcache                 1.1.0            py37h7b6447c_0  \r\n",
      "filelock                  3.0.12                     py_0  \r\n",
      "flake8                    3.7.9                    py37_0  \r\n",
      "flask                     1.1.1                      py_0  \r\n",
      "fontconfig                2.13.0               h9420a91_0  \r\n",
      "freetype                  2.9.1                h8a8886c_1  \r\n",
      "fribidi                   1.0.5                h7b6447c_0  \r\n",
      "fsspec                    0.6.2                      py_0  \r\n",
      "future                    0.18.2                   py37_0  \r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "gensim                    3.8.3                    pypi_0    pypi\r\n",
      "get_terminal_size         1.0.0                haa9412d_0  \r\n",
      "gevent                    1.4.0            py37h7b6447c_0  \r\n",
      "glib                      2.63.1               h5a9c865_0  \r\n",
      "glob2                     0.7                        py_0  \r\n",
      "gmp                       6.1.2                h6c8ec71_1  \r\n",
      "gmpy2                     2.0.8            py37h10f8cd9_2  \r\n",
      "google-auth               1.19.2                   pypi_0    pypi\r\n",
      "google-auth-oauthlib      0.4.1                    pypi_0    pypi\r\n",
      "google-pasta              0.2.0                    pypi_0    pypi\r\n",
      "gpustat                   0.6.0                    pypi_0    pypi\r\n",
      "graphite2                 1.3.13               h23475e2_0  \r\n",
      "greenlet                  0.4.15           py37h7b6447c_0  \r\n",
      "grpcio                    1.30.0                   pypi_0    pypi\r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb453b48_1  \r\n",
      "h5py                      2.10.0           py37h7918eee_0  \r\n",
      "harfbuzz                  1.8.8                hffaf4a1_0  \r\n",
      "hdf5                      1.10.4               hb1b8bf9_0  \r\n",
      "heapdict                  1.0.1                      py_0  \r\n",
      "html5lib                  1.0.1                    py37_0  \r\n",
      "hypothesis                5.5.4                      py_0  \r\n",
      "icu                       58.2                 h9c2bf20_1  \r\n",
      "idna                      2.8                      py37_0  \r\n",
      "imageio                   2.6.1                    py37_0  \r\n",
      "imagesize                 1.2.0                      py_0  \r\n",
      "importlib_metadata        1.5.0                    py37_0  \r\n",
      "intel-openmp              2020.0                      166  \r\n",
      "intervaltree              3.0.2                      py_0  \r\n",
      "ipykernel                 5.1.4            py37h39e3cac_0  \r\n",
      "ipython                   7.12.0           py37h5ca1d4c_0  \r\n",
      "ipython_genutils          0.2.0                    py37_0  \r\n",
      "ipywidgets                7.5.1                      py_0  \r\n",
      "isort                     4.3.21                   py37_0  \r\n",
      "itsdangerous              1.1.0                    py37_0  \r\n",
      "jbig                      2.1                  hdba287a_0  \r\n",
      "jdcal                     1.4.1                      py_0  \r\n",
      "jedi                      0.14.1                   py37_0  \r\n",
      "jeepney                   0.4.2                      py_0  \r\n",
      "jinja2                    2.11.1                     py_0  \r\n",
      "jmespath                  0.10.0                   pypi_0    pypi\r\n",
      "joblib                    0.14.1                     py_0  \r\n",
      "jpeg                      9b                   h024ee3a_2  \r\n",
      "json5                     0.9.1                      py_0  \r\n",
      "jsonschema                3.2.0                    py37_0  \r\n",
      "jupyter                   1.0.0                    py37_7  \r\n",
      "jupyter_client            5.3.4                    py37_0  \r\n",
      "jupyter_console           6.1.0                      py_0  \r\n",
      "jupyter_core              4.6.1                    py37_0  \r\n",
      "jupyterlab                1.2.6              pyhf63ae98_0  \r\n",
      "jupyterlab_server         1.0.6                      py_0  \r\n",
      "keras                     2.4.3                    pypi_0    pypi\r\n",
      "keras-applications        1.0.8                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.1.2                    pypi_0    pypi\r\n",
      "keyring                   21.1.0                   py37_0  \r\n",
      "kiwisolver                1.1.0            py37he6710b0_0  \r\n",
      "krb5                      1.17.1               h173b8e3_0  \r\n",
      "lazy-object-proxy         1.4.3            py37h7b6447c_0  \r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "libarchive                3.3.3                h5d8350f_5  \r\n",
      "libcurl                   7.68.0               h20c2e04_0  \r\n",
      "libedit                   3.1.20181209         hc058e9b_0  \r\n",
      "libffi                    3.2.1                hd88cf55_4  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \r\n",
      "liblief                   0.9.0                h7725739_2  \r\n",
      "libpng                    1.6.37               hbc83047_0  \r\n",
      "libsodium                 1.0.16               h1bed415_0  \r\n",
      "libspatialindex           1.9.3                he6710b0_0  \r\n",
      "libssh2                   1.8.2                h1ba5d50_0  \r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libtiff                   4.1.0                h2733197_0  \r\n",
      "libtool                   2.4.6                h7b6447c_5  \r\n",
      "libuuid                   1.0.3                h1bed415_2  \r\n",
      "libxcb                    1.13                 h1bed415_1  \r\n",
      "libxml2                   2.9.9                hea5a465_1  \r\n",
      "libxslt                   1.1.33               h7d1a2b0_0  \r\n",
      "llvmlite                  0.31.0           py37hd408876_0  \r\n",
      "locket                    0.2.0                    py37_1  \r\n",
      "lxml                      4.5.0            py37hefd8a0e_0  \r\n",
      "lz4-c                     1.8.1.2              h14c3975_0  \r\n",
      "lzo                       2.10                 h49e0be7_2  \r\n",
      "markdown                  3.2.2                    pypi_0    pypi\r\n",
      "markupsafe                1.1.1            py37h7b6447c_0  \r\n",
      "matplotlib                3.1.3                    py37_0  \r\n",
      "matplotlib-base           3.1.3            py37hef1b27d_0  \r\n",
      "mccabe                    0.6.1                    py37_1  \r\n",
      "mistune                   0.8.4            py37h7b6447c_0  \r\n",
      "mkl                       2020.0                      166  \r\n",
      "mkl-service               2.3.0            py37he904b0f_0  \r\n",
      "mkl_fft                   1.0.15           py37ha843d7b_0  \r\n",
      "mkl_random                1.1.0            py37hd6b4f25_0  \r\n",
      "mock                      4.0.1                      py_0  \r\n",
      "more-itertools            8.2.0                      py_0  \r\n",
      "mpc                       1.1.0                h10f8cd9_1  \r\n",
      "mpfr                      4.0.1                hdf1c602_3  \r\n",
      "mpmath                    1.1.0                    py37_0  \r\n",
      "msgpack-python            0.6.1            py37hfd86e86_1  \r\n",
      "multipledispatch          0.6.0                    py37_0  \r\n",
      "murmurhash                1.0.2                    pypi_0    pypi\r\n",
      "navigator-updater         0.2.1                    py37_0  \r\n",
      "nbconvert                 5.6.1                    py37_0  \r\n",
      "nbformat                  5.0.4                      py_0  \r\n",
      "ncurses                   6.2                  he6710b0_0  \r\n",
      "networkx                  2.4                        py_0  \r\n",
      "nltk                      3.4.5                    py37_0  \r\n",
      "nose                      1.3.7                    py37_2  \r\n",
      "notebook                  6.0.3                    py37_0  \r\n",
      "numba                     0.48.0           py37h0573a6f_0  \r\n",
      "numexpr                   2.7.1            py37h423224d_0  \r\n",
      "numpy                     1.18.1           py37h4f9e942_0  \r\n",
      "numpy-base                1.18.1           py37hde5b4d6_1  \r\n",
      "numpydoc                  0.9.2                      py_0  \r\n",
      "nvidia-ml-py3             7.352.0                  pypi_0    pypi\r\n",
      "oauthlib                  3.1.0                    pypi_0    pypi\r\n",
      "olefile                   0.46                     py37_0  \r\n",
      "openpyxl                  3.0.3                      py_0  \r\n",
      "openssl                   1.1.1d               h7b6447c_4  \r\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\r\n",
      "packaging                 20.1                       py_0  \r\n",
      "pandas                    1.0.1            py37h0573a6f_0  \r\n",
      "pandoc                    2.2.3.2                       0  \r\n",
      "pandocfilters             1.4.2                    py37_1  \r\n",
      "pango                     1.42.4               h049681c_0  \r\n",
      "parso                     0.5.2                      py_0  \r\n",
      "partd                     1.1.0                      py_0  \r\n",
      "patchelf                  0.10                 he6710b0_0  \r\n",
      "path                      13.1.0                   py37_0  \r\n",
      "path.py                   12.4.0                        0  \r\n",
      "pathlib2                  2.3.5                    py37_0  \r\n",
      "pathtools                 0.1.2                      py_1  \r\n",
      "patsy                     0.5.1                    py37_0  \r\n",
      "pcre                      8.43                 he6710b0_0  \r\n",
      "pep8                      1.7.1                    py37_0  \r\n",
      "pexpect                   4.8.0                    py37_0  \r\n",
      "pickleshare               0.7.5                    py37_0  \r\n",
      "pillow                    7.0.0            py37hb39fc2d_0  \r\n",
      "pip                       20.0.2                   py37_1  \r\n",
      "pixman                    0.38.0               h7b6447c_0  \r\n",
      "pkginfo                   1.5.0.1                  py37_0  \r\n",
      "plac                      1.1.3                    pypi_0    pypi\r\n",
      "pluggy                    0.13.1                   py37_0  \r\n",
      "ply                       3.11                     py37_0  \r\n",
      "preshed                   3.0.2                    pypi_0    pypi\r\n",
      "prettytable               0.7.2                    pypi_0    pypi\r\n",
      "prometheus_client         0.7.1                      py_0  \r\n",
      "prompt_toolkit            3.0.3                      py_0  \r\n",
      "protobuf                  3.12.2                   pypi_0    pypi\r\n",
      "psutil                    5.6.7            py37h7b6447c_0  \r\n",
      "ptyprocess                0.6.0                    py37_0  \r\n",
      "py                        1.8.1                      py_0  \r\n",
      "py-lief                   0.9.0            py37h7725739_2  \r\n",
      "pyasn1                    0.4.8                    pypi_0    pypi\r\n",
      "pyasn1-modules            0.2.8                    pypi_0    pypi\r\n",
      "pycodestyle               2.5.0                    py37_0  \r\n",
      "pycosat                   0.6.3            py37h7b6447c_0  \r\n",
      "pycparser                 2.19                     py37_0  \r\n",
      "pycrypto                  2.6.1            py37h14c3975_9  \r\n",
      "pycurl                    7.43.0.5         py37h1ba5d50_0  \r\n",
      "pydocstyle                4.0.1                      py_0  \r\n",
      "pyecharts                 1.8.1                    pypi_0    pypi\r\n",
      "pyflakes                  2.1.1                    py37_0  \r\n",
      "pygments                  2.5.2                      py_0  \r\n",
      "pylint                    2.4.4                    py37_0  \r\n",
      "pyodbc                    4.0.30           py37he6710b0_0  \r\n",
      "pyopenssl                 19.1.0                   py37_0  \r\n",
      "pyparsing                 2.4.6                      py_0  \r\n",
      "pyqt                      5.9.2            py37h05f1152_2  \r\n",
      "pyrsistent                0.15.7           py37h7b6447c_0  \r\n",
      "pysocks                   1.7.1                    py37_0  \r\n",
      "pytables                  3.6.1            py37h71ec239_0  \r\n",
      "pytest                    5.3.5                    py37_0  \r\n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \r\n",
      "pytest-astropy            0.8.0                      py_0  \r\n",
      "pytest-astropy-header     0.1.2                      py_0  \r\n",
      "pytest-doctestplus        0.5.0                      py_0  \r\n",
      "pytest-openfiles          0.4.0                      py_0  \r\n",
      "pytest-remotedata         0.3.2                    py37_0  \r\n",
      "python                    3.7.6                h0371630_2  \r\n",
      "python-dateutil           2.8.1                      py_0  \r\n",
      "python-jsonrpc-server     0.3.4                      py_0  \r\n",
      "python-language-server    0.31.7                   py37_0  \r\n",
      "python-libarchive-c       2.8                     py37_13  \r\n",
      "pytz                      2019.3                     py_0  \r\n",
      "pywavelets                1.1.1            py37h7b6447c_0  \r\n",
      "pyxdg                     0.26                       py_0  \r\n",
      "pyyaml                    5.3              py37h7b6447c_0  \r\n",
      "pyzmq                     18.1.1           py37he6710b0_0  \r\n",
      "qdarkstyle                2.8                        py_0  \r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtawesome                 0.6.1                      py_0  \r\n",
      "qtconsole                 4.6.0                      py_1  \r\n",
      "qtpy                      1.9.0                      py_0  \r\n",
      "readline                  7.0                  h7b6447c_5  \r\n",
      "requests                  2.22.0                   py37_1  \r\n",
      "requests-oauthlib         1.3.0                    pypi_0    pypi\r\n",
      "ripgrep                   11.0.2               he32d670_0  \r\n",
      "rope                      0.16.0                     py_0  \r\n",
      "rsa                       4.6                      pypi_0    pypi\r\n",
      "rtree                     0.9.3                    py37_0  \r\n",
      "ruamel_yaml               0.15.87          py37h7b6447c_0  \r\n",
      "s3transfer                0.3.3                    pypi_0    pypi\r\n",
      "scikit-image              0.16.2           py37h0573a6f_0  \r\n",
      "scikit-learn              0.22.1           py37hd81dba3_0  \r\n",
      "scipy                     1.4.1            py37h0b6359f_0  \r\n",
      "seaborn                   0.10.0                     py_0  \r\n",
      "secretstorage             3.1.2                    py37_0  \r\n",
      "send2trash                1.5.0                    py37_0  \r\n",
      "setuptools                45.2.0                   py37_0  \r\n",
      "simplegeneric             0.8.1                    py37_2  \r\n",
      "simplejson                3.17.2                   pypi_0    pypi\r\n",
      "singledispatch            3.4.0.3                  py37_0  \r\n",
      "sip                       4.19.8           py37hf484d3e_0  \r\n",
      "six                       1.14.0                   py37_0  \r\n",
      "smart-open                2.1.0                    pypi_0    pypi\r\n",
      "snappy                    1.1.7                hbae5bb6_3  \r\n",
      "snowballstemmer           2.0.0                      py_0  \r\n",
      "sortedcollections         1.1.2                    py37_0  \r\n",
      "sortedcontainers          2.1.0                    py37_0  \r\n",
      "soupsieve                 1.9.5                    py37_0  \r\n",
      "spacy                     2.3.2                    pypi_0    pypi\r\n",
      "sphinx                    2.4.0                      py_0  \r\n",
      "sphinxcontrib             1.0                      py37_1  \r\n",
      "sphinxcontrib-applehelp   1.0.1                      py_0  \r\n",
      "sphinxcontrib-devhelp     1.0.1                      py_0  \r\n",
      "sphinxcontrib-htmlhelp    1.0.2                      py_0  \r\n",
      "sphinxcontrib-jsmath      1.0.1                      py_0  \r\n",
      "sphinxcontrib-qthelp      1.0.2                      py_0  \r\n",
      "sphinxcontrib-serializinghtml 1.1.3                      py_0  \r\n",
      "sphinxcontrib-websupport  1.2.0                      py_0  \r\n",
      "spyder                    4.0.1                    py37_0  \r\n",
      "spyder-kernels            1.8.1                    py37_0  \r\n",
      "sqlalchemy                1.3.13           py37h7b6447c_0  \r\n",
      "sqlite                    3.31.1               h7b6447c_0  \r\n",
      "srsly                     1.0.2                    pypi_0    pypi\r\n",
      "statsmodels               0.11.0           py37h7b6447c_0  \r\n",
      "sympy                     1.5.1                    py37_0  \r\n",
      "tabulate                  0.8.7                    pypi_0    pypi\r\n",
      "tbb                       2020.0               hfd86e86_0  \r\n",
      "tblib                     1.6.0                      py_0  \r\n",
      "tensorboard               2.0.2                    pypi_0    pypi\r\n",
      "tensorboard-plugin-wit    1.7.0                    pypi_0    pypi\r\n",
      "tensorflow-estimator      2.0.1                    pypi_0    pypi\r\n",
      "tensorflow-gpu            2.0.0                    pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.8.3                    py37_0  \r\n",
      "testpath                  0.4.4                      py_0  \r\n",
      "thinc                     7.4.1                    pypi_0    pypi\r\n",
      "tk                        8.6.8                hbc83047_0  \r\n",
      "toolz                     0.10.0                     py_0  \r\n",
      "tornado                   6.0.3            py37h7b6447c_3  \r\n",
      "tqdm                      4.42.1                     py_0  \r\n",
      "traitlets                 4.3.3                    py37_0  \r\n",
      "ujson                     1.35             py37h14c3975_0  \r\n",
      "unicodecsv                0.14.1                   py37_0  \r\n",
      "unixodbc                  2.3.7                h14c3975_0  \r\n",
      "urllib3                   1.25.8                   py37_0  \r\n",
      "wasabi                    0.7.1                    pypi_0    pypi\r\n",
      "watchdog                  0.10.2                   py37_0  \r\n",
      "wcwidth                   0.1.8                      py_0  \r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "werkzeug                  1.0.0                      py_0  \r\n",
      "wheel                     0.34.2                   py37_0  \r\n",
      "widgetsnbextension        3.5.1                    py37_0  \r\n",
      "wrapt                     1.11.2           py37h7b6447c_0  \r\n",
      "wurlitzer                 2.0.0                    py37_0  \r\n",
      "xlrd                      1.2.0                    py37_0  \r\n",
      "xlsxwriter                1.2.7                      py_0  \r\n",
      "xlwt                      1.3.0                    py37_0  \r\n",
      "xmltodict                 0.12.0                     py_0  \r\n",
      "xz                        5.2.4                h14c3975_4  \r\n",
      "yaml                      0.1.7                had09818_2  \r\n",
      "yapf                      0.28.0                     py_0  \r\n",
      "zeromq                    4.3.1                he6710b0_3  \r\n",
      "zict                      1.0.0                      py_0  \r\n",
      "zipp                      2.2.0                      py_0  \r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n",
      "zstd                      1.3.7                h0b5b093_0  \r\n"
     ]
    }
   ],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ec3cd4dcdc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"NER_dataset/tran_X.json\", \"r\") as f:\n",
    "    X = json.load(f)\n",
    "    \n",
    "with open(\"NER_dataset/tran_Y.json\", \"r\") as f:\n",
    "    Y = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buliding training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "for ind in range(len(X)):\n",
    "    if ind % 7 == 0:\n",
    "        test_x.append( X[ind] )\n",
    "        test_y.append( Y[ind] )\n",
    "\n",
    "    else:\n",
    "        train_x.append( X[ind] )\n",
    "        train_y.append( Y[ind] )\n",
    "\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x for x in train_x if len(x) > 2 and len(x) < 120]\n",
    "train_y = [x for x in train_y if len(x) > 2 and len(x) < 120]\n",
    "\n",
    "test_x = [x for x in test_x if len(x) > 2 and len(x) < 120]\n",
    "test_y = [x for x in test_y if len(x) > 2 and len(x) < 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:\n",
      "['Experience', 'working', 'on', 'front', '-', 'back', '-', 'end', ',', 'or', 'full', '-', 'stack', 'web', 'development', 'projects', '.']\n",
      "label:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print('sentence:')\n",
    "print( train_x[0] )\n",
    "print('label:')\n",
    "print( train_y[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset_size: 525\n",
      "testset_size: 88\n"
     ]
    }
   ],
   "source": [
    "print( 'trainset_size:',len( train_x ) )\n",
    "print( 'testset_size:',len( test_x ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import Tokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_bilstm_crf:\n",
    "    def __init__(self, max_seq_length, batch_size, epochs, lstm_dim):\n",
    "        self.label = {}\n",
    "        self._label = {}\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lstmDim = lstm_dim\n",
    "        self.LoadLabel()\n",
    "        self.model = self.Model()\n",
    "\n",
    "    ##############################################\n",
    "    def LoadLabel(self):\n",
    "        #label\n",
    "        label_path = r\"uncased_L-2_H-128_A-2/tag_dict.txt\"\n",
    "        f_label = open(label_path, 'r+', encoding='utf-8')\n",
    "        for line in f_label:\n",
    "            content = line.strip().split()\n",
    "            self.label[content[0].strip()] = content[1].strip()\n",
    "            self._label[content[1].strip()] = content[0].strip()\n",
    "            \n",
    "        #dict\n",
    "        self.vocab = {}\n",
    "        vocab_path = r\"uncased_L-2_H-128_A-2/vocab.txt\"\n",
    "        with open(vocab_path, 'r+', encoding='utf-8') as f_vocab:\n",
    "            for line in f_vocab.readlines():\n",
    "                self.vocab[line.strip()] = len(self.vocab)\n",
    "\n",
    "    def Model(self):\n",
    "        model_path = r\"uncased_L-2_H-128_A-2/\"\n",
    "        bert = load_trained_model_from_checkpoint(\n",
    "            model_path + \"bert_config.json\",\n",
    "            model_path + \"bert_model.ckpt\",\n",
    "            seq_len=self.max_seq_length\n",
    "            )\n",
    "        #make bert layer trainable\n",
    "        for layer in bert.layers:\n",
    "            layer.trainable = True\n",
    "        x1 = Input(shape=(None,))\n",
    "        x2 = Input(shape=(None,))\n",
    "        bert_out = bert([x1, x2])\n",
    "        lstm_out = Bidirectional(LSTM(self.lstmDim,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2,\n",
    "                                         recurrent_dropout=0.2))(bert_out)\n",
    "        crf_out = CRF(len(self.label), sparse_target=True)(lstm_out)\n",
    "        model = Model([x1, x2], crf_out)\n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(1e-4),\n",
    "            loss=crf_loss,\n",
    "            metrics=[crf_accuracy]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def PreProcessInputData(self, text):\n",
    "        word_labels = []\n",
    "        seq_types = []\n",
    "        \n",
    "        for sequence in text:\n",
    "            len_text = len(sequence)\n",
    "            \n",
    "            ###########################################\n",
    "            temp_word_labels = []\n",
    "            \n",
    "            temp_word_labels.append( 101 )            \n",
    "            for w in sequence:\n",
    "                temp_word_labels.append( self.vocab.get(w,1) )\n",
    "            temp_word_labels.append( 102 )\n",
    "            \n",
    "            ###########################################\n",
    "            temp_seq_types = [1] * len(temp_word_labels) +  [0] * (self.max_seq_length - len( temp_word_labels ))\n",
    "            temp_word_labels = temp_word_labels + [0] * (self.max_seq_length - len( temp_word_labels ))\n",
    "            \n",
    "            word_labels.append( temp_word_labels )\n",
    "            seq_types.append( temp_seq_types )\n",
    "            \n",
    "        return word_labels, seq_types\n",
    "\n",
    "\n",
    "    def PreProcessOutputData(self, text):\n",
    "        tags = []\n",
    "        for line in text:\n",
    "            tag = [0]\n",
    "            for item in line:\n",
    "                tag.append(int(self.label[item.strip()]))\n",
    "            tag.append(0)\n",
    "            tags.append(tag)\n",
    "\n",
    "        pad_tags = pad_sequences(tags, maxlen=self.max_seq_length, padding=\"post\", truncating=\"post\")\n",
    "        result_tags = np.expand_dims(pad_tags, 2)\n",
    "        return result_tags\n",
    "\n",
    "    def TrainModel(self, train_data):\n",
    "        input_train, result_train = train_data\n",
    "        input_test, result_test = test_data\n",
    "        \n",
    "        #训练集\n",
    "        input_train_labels, input_train_types = self.PreProcessInputData(input_train)\n",
    "        result_train = self.PreProcessOutputData(result_train)\n",
    "        \n",
    "        #测试集\n",
    "#         input_test_labels, input_test_types = self.PreProcessInputData(input_test)\n",
    "#         result_test = self.PreProcessOutputData(result_test)\n",
    "        \n",
    "        history = self.model.fit(x=[input_train_labels, input_train_types],\n",
    "                       y=result_train,\n",
    "                       validation_split=0.2,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       shuffle=True,\n",
    "                       verbose=1,\n",
    "                       class_weight = 'auto')\n",
    "        \n",
    "        self.model.save('NER_model/my_NER_model')\n",
    "        return\n",
    "\n",
    "    def Id2Label(self, ids):\n",
    "        result = []\n",
    "        for id in ids:\n",
    "            result.append(self._label[str(id)])\n",
    "        return result\n",
    "\n",
    "    def Vector2Id(self, tags):\n",
    "        result = []\n",
    "        for tag in tags:\n",
    "            result.append(np.argmax(tag))\n",
    "        return result\n",
    "\n",
    "    def ModelPredict(self, sentence):\n",
    "        labels, types = self.PreProcessInputData([sentence])\n",
    "        self.model.load_weights('NER_model/my_NER_model')\n",
    "        tags = self.model.predict([labels, types])[0]\n",
    "        \n",
    "        result = []\n",
    "        for i in range(1, len(sentence) + 1):\n",
    "            result.append(tags[i])\n",
    "        result = self.Vector2Id(result)\n",
    "        tag = self.Id2Label(result)\n",
    "        return tag\n",
    "\n",
    "    def EvalModel(self, valid_data):\n",
    "        input_valid, result_valid = valid_data\n",
    "        #训练集\n",
    "        input_valid_labels, input_valid_types = self.PreProcessInputData(input_valid)\n",
    "        result_valid = self.PreProcessOutputData(result_valid)\n",
    "        \n",
    "        res = ( self.model.evaluate(x=[input_valid_labels, input_valid_types],\n",
    "                           y=result_valid,batch_size=self.batch_size) )\n",
    "        print(res)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             4320256     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 128)    98816       model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "crf_1 (CRF)                     (None, None, 5)      680         bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 4,419,752\n",
      "Trainable params: 4,419,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 420 samples, validate on 105 samples\n",
      "Epoch 1/20\n",
      "420/420 [==============================] - 31s 74ms/step - loss: 12.5269 - crf_accuracy: 0.4824 - val_loss: 11.4135 - val_crf_accuracy: 0.6848\n",
      "Epoch 2/20\n",
      "420/420 [==============================] - 21s 49ms/step - loss: 11.8995 - crf_accuracy: 0.7408 - val_loss: 11.1965 - val_crf_accuracy: 0.6858\n",
      "Epoch 3/20\n",
      "420/420 [==============================] - 25s 59ms/step - loss: 11.7447 - crf_accuracy: 0.7793 - val_loss: 11.0079 - val_crf_accuracy: 0.7749\n",
      "Epoch 4/20\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 11.6177 - crf_accuracy: 0.8062 - val_loss: 10.9335 - val_crf_accuracy: 0.7926\n",
      "Epoch 5/20\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 11.5420 - crf_accuracy: 0.8304 - val_loss: 10.8657 - val_crf_accuracy: 0.8320\n",
      "Epoch 6/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.4888 - crf_accuracy: 0.8599 - val_loss: 10.8507 - val_crf_accuracy: 0.8450\n",
      "Epoch 7/20\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 11.4422 - crf_accuracy: 0.8766 - val_loss: 10.8055 - val_crf_accuracy: 0.8728\n",
      "Epoch 8/20\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 11.4001 - crf_accuracy: 0.8882 - val_loss: 10.7993 - val_crf_accuracy: 0.8771\n",
      "Epoch 9/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.3766 - crf_accuracy: 0.8966 - val_loss: 10.7695 - val_crf_accuracy: 0.8722\n",
      "Epoch 10/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.3586 - crf_accuracy: 0.9049 - val_loss: 10.7989 - val_crf_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "420/420 [==============================] - 23s 55ms/step - loss: 11.3432 - crf_accuracy: 0.9039 - val_loss: 10.7653 - val_crf_accuracy: 0.8818\n",
      "Epoch 12/20\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 11.3193 - crf_accuracy: 0.9157 - val_loss: 10.7610 - val_crf_accuracy: 0.8858\n",
      "Epoch 13/20\n",
      "420/420 [==============================] - 22s 52ms/step - loss: 11.3057 - crf_accuracy: 0.9194 - val_loss: 10.7611 - val_crf_accuracy: 0.8901\n",
      "Epoch 14/20\n",
      "420/420 [==============================] - 21s 50ms/step - loss: 11.2886 - crf_accuracy: 0.9255 - val_loss: 10.7611 - val_crf_accuracy: 0.8852\n",
      "Epoch 15/20\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 11.2819 - crf_accuracy: 0.9258 - val_loss: 10.7533 - val_crf_accuracy: 0.8919\n",
      "Epoch 16/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.2668 - crf_accuracy: 0.9320 - val_loss: 10.7748 - val_crf_accuracy: 0.8916\n",
      "Epoch 17/20\n",
      "420/420 [==============================] - 20s 49ms/step - loss: 11.2551 - crf_accuracy: 0.9339 - val_loss: 10.7705 - val_crf_accuracy: 0.8910\n",
      "Epoch 18/20\n",
      "420/420 [==============================] - 22s 52ms/step - loss: 11.2426 - crf_accuracy: 0.9401 - val_loss: 10.7719 - val_crf_accuracy: 0.8891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.2341 - crf_accuracy: 0.9432 - val_loss: 10.7835 - val_crf_accuracy: 0.8905\n",
      "Epoch 20/20\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 11.2296 - crf_accuracy: 0.9443 - val_loss: 10.7816 - val_crf_accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "train_data = ( train_x, train_y )\n",
    "test_data  = ( test_x, test_y )\n",
    "\n",
    "#模型\n",
    "max_seq_length = 128\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lstmDim = 64\n",
    "model = bert_bilstm_crf( max_seq_length, batch_size, epochs, lstmDim )\n",
    "model.TrainModel( train_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predict( model, tem):\n",
    "    predict_list = model.ModelPredict( [w.lower() for w in tem] )\n",
    "\n",
    "    print()\n",
    "    print( '【Extract Result】', end='' )\n",
    "    i = 0\n",
    "    for i in range( len( predict_list ) ):\n",
    "        if predict_list[i] == 'B':\n",
    "            print( '|',tem[i],'',end='' )\n",
    "            \n",
    "        if predict_list[i] == 'I':\n",
    "            print( tem[i],'',end='' )\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience in commonly used for data analysis such as Python , R , Julia , or SAS .\n",
      "\n",
      "【Real Result】| data analysis | Python | R | Julia | SAS \n",
      "【Extract Result】| data analysis | Python | R | Julia \n",
      "========================================================================================================================\n",
      "Design solutions by mapping client business processes and challenges to an end - to - end solution on the platform utilizing data analytics , machine learning , and artificial intelligence to predict outcomes and prescribe actions\n",
      "\n",
      "【Real Result】| data analytics | machine learning | artificial intelligence \n",
      "【Extract Result】| data analytics | machine learning | artificial intelligence \n",
      "========================================================================================================================\n",
      "Research and keep track of industry trends in Data Analytics / Statistic Modeling / Predictive Modeling / AI / Algorithms to ensure that the department is evaluating new techniques .\n",
      "\n",
      "【Real Result】| Data Analytics | Statistic Modeling | Predictive Modeling | AI | Algorithms \n",
      "【Extract Result】| Data Analytics | Statistic | Modeling | Predictive Modeling Algorithms \n",
      "========================================================================================================================\n",
      "Data Science experience   should have experience in Hadoop , Spark & Hive Building models for highly imbalanced data sets\n",
      "\n",
      "【Real Result】| Hadoop | Spark | Hive \n",
      "【Extract Result】Science | Hadoop | Spark Hive data sets \n",
      "========================================================================================================================\n",
      "Graduate degree in analytically driven fields such as mathematics , statistics , physics , economics , data science , computer science , operations research or actuarial science .\n",
      "\n",
      "【Real Result】| mathematics | statistics | physics | economics | data science | computer science | operations research | actuarial science \n",
      "【Extract Result】| mathematics | statistics | physics | economics | data science | computer science | operations research | actuarial science \n",
      "========================================================================================================================\n",
      "Cognitive and Communications Skill - Highly articulate , built upon an underlying fundamental clarity of thought .\n",
      "\n",
      "【Real Result】| Cognitive and Communications Skill \n",
      "【Extract Result】| Cognitive | Communications Skill - articulate \n",
      "========================================================================================================================\n",
      "Proficient with Python , R , SQL Server , MongoDB .\n",
      "\n",
      "【Real Result】| Python | R | SQL Server | MongoDB \n",
      "【Extract Result】| Python | R | SQL Server | MongoDB \n",
      "========================================================================================================================\n",
      "The focus of this position is to develop analytical problems and models , discover insights and identify opportunities through use of statistical , algorithmic , mining and visualization techniques .\n",
      "\n",
      "【Real Result】| statistical | algorithmic | mining | visualization \n",
      "【Extract Result】| analytical problems | statistical | algorithmic | mining | visualization \n",
      "========================================================================================================================\n",
      "Work with Junior analyst and developers to build our BI and analytics tools .\n",
      "\n",
      "【Real Result】| BI | analytics \n",
      "【Extract Result】\n",
      "========================================================================================================================\n",
      "5 + years of experience with data analytics or data science\n",
      "\n",
      "【Real Result】| data analytics | data science \n",
      "【Extract Result】| data analytics | data science \n",
      "========================================================================================================================\n",
      "HTML , CSS , JavaScript , XML , JSON\n",
      "\n",
      "【Real Result】| HTML | CSS | JavaScript | XML | JSON \n",
      "【Extract Result】| CSS | JavaScript | XML | JSON \n",
      "========================================================================================================================\n",
      "Effective communication skills and ability to explain how your insights and recommendations are directly linked to business optimization and opportunity , including presentation of complex analytical concepts to a non - technical audience ( up to senior management levels ) .\n",
      "\n",
      "【Real Result】| communication skills \n",
      "【Extract Result】| communication skills optimization | analytical \n",
      "========================================================================================================================\n",
      "Prior data science experience working with languages like R , Python , or Java Ability to deliver in a fast - paced , self - directed environment Ability to learn new concepts , tools , languages , and models An analytical mindset\n",
      "\n",
      "【Real Result】| R | Python | Java \n",
      "【Extract Result】| data science | languages | R | Python | Java | fast - paced | self - directed environment concepts | tools | languages | analytical mindset \n",
      "========================================================================================================================\n",
      "Excellent written and verbal communication skills Qualifications Education Required Bachelors or better in Mathematics or related field .\n",
      "\n",
      "【Real Result】| written and verbal communication skills | Mathematics \n",
      "【Extract Result】| written verbal communication skills | Bachelors | Mathematics \n",
      "========================================================================================================================\n",
      "As a senior data scientist in Wells Fargo Enterprise Complaints Data , Analytics , and Reporting ( CDAR )\n",
      "\n",
      "【Real Result】| Complaints Data | Analytics | Reporting | CDAR \n",
      "【Extract Result】scientist Enterprise Complaints Data | Analytics | Reporting | CDAR \n",
      "========================================================================================================================\n",
      "Experience with Jupyter Notebooks\n",
      "\n",
      "【Real Result】| Jupyter Notebooks \n",
      "【Extract Result】| Jupyter Notebooks \n",
      "========================================================================================================================\n",
      "Use Hive , Scala , Java or Python to utilize Hadoop / Spark to process large - scale datasets\n",
      "\n",
      "【Real Result】| Hive | Scala | Java | Python | Hadoop | Spark \n",
      "【Extract Result】| Hive | Scala | Java | Python | Hadoop \n",
      "========================================================================================================================\n",
      "Bachelor 's degree in Computer Science , Statistics or STEM related field ; Master 's degree preferred\n",
      "\n",
      "【Real Result】| Bachelor 's degree | Computer Science | Statistics | STEM | Master 's degree \n",
      "【Extract Result】| 's degree | Computer Science | Statistics | STEM | Master | 's degree \n",
      "========================================================================================================================\n",
      "Apply statistical analysis and visualization techniques to various data , such as hierarchical clustering , T - distributed Stochastic Neighbor Embedding ( t - SNE ) , principal components analysis ( PCA )\n",
      "\n",
      "【Real Result】| statistical analysis | visualization | hierarchical clustering | T - distributed Stochastic Neighbor Embedding | t - SNE | principal components analysis | PCA \n",
      "【Extract Result】| statistical analysis | visualization | data | hierarchical clustering | distributed Stochastic Neighbor Embedding | - SNE | principal components analysis | PCA \n",
      "========================================================================================================================\n",
      "A PhD in Economics , Econometrics , Business , or related field , and 1 + years of experience applying econometric methods in retail .\n",
      "\n",
      "【Real Result】| Economics | Econometrics | Business | econometric methods \n",
      "【Extract Result】| Econometrics | Business | econometric \n",
      "========================================================================================================================\n",
      "Our advanced analytics algorithms and models are becoming a core part of Cummins physical and digital products every day .\n",
      "\n",
      "【Real Result】| analytics algorithms \n",
      "【Extract Result】analytics algorithms physical \n",
      "========================================================================================================================\n",
      "Expertise in R or Python\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| R | Python \n",
      "【Extract Result】| R | Python \n",
      "========================================================================================================================\n",
      "Experience with data acquisition tools ( e.g. SQL , Apache Spark etc . ) , large datasets ( Hadoop ) and data mining\n",
      "\n",
      "【Real Result】| data acquisition tools | SQL | Apache Spark | large datasets | Hadoop | data mining \n",
      "【Extract Result】| data acquisition tools | e.g. SQL | Apache Spark | Hadoop | data mining \n",
      "========================================================================================================================\n",
      "Possess basic understanding of system requirements for the deployment of the latest versions of R and Python and Scripting\n",
      "\n",
      "【Real Result】| R | Python | Scripting \n",
      "【Extract Result】| Python Scripting \n",
      "========================================================================================================================\n",
      "Develops and validates statistical forecasting models and tools .\n",
      "\n",
      "【Real Result】| statistical forecasting models \n",
      "【Extract Result】| statistical forecasting models \n",
      "========================================================================================================================\n",
      "1 + year experience with Tableau or Power BI\n",
      "\n",
      "【Real Result】| Tableau | Power BI \n",
      "【Extract Result】| Tableau | Power BI \n",
      "========================================================================================================================\n",
      "Develop and deliver advanced statistical and mathematical models to support fact - based decision making within the organization\n",
      "\n",
      "【Real Result】| mathematical models \n",
      "【Extract Result】| statistical | mathematical models decision \n",
      "========================================================================================================================\n",
      "RDBMS SQL Development .\n",
      "\n",
      "【Real Result】| RDBMS SQL \n",
      "【Extract Result】| SQL Development \n",
      "========================================================================================================================\n",
      "Experience with SQL .\n",
      "\n",
      "【Real Result】| SQL \n",
      "【Extract Result】| SQL \n",
      "========================================================================================================================\n",
      "Local language skills to an advanced level ( spoken and written ) , with complete fluency in English .\n",
      "\n",
      "【Real Result】| English \n",
      "【Extract Result】| language skills | spoken | written \n",
      "========================================================================================================================\n",
      "Working with modern distributed analytics systems , complex data , and challenging requests , you will have the opportunity to apply complex code , and possibly move into a Methodology role within IQVIA .\n",
      "\n",
      "【Real Result】| distributed analytics \n",
      "【Extract Result】| distributed analytics systems | data | IQVIA \n",
      "========================================================================================================================\n",
      "Experience in interpreting results from statistical and mathematical models .\n",
      "\n",
      "【Real Result】| statistical and mathematical models \n",
      "【Extract Result】| interpreting | statistical | mathematical models \n",
      "========================================================================================================================\n",
      "Knowledge in at least one of the following areas : predictive modeling , machine learning , experimentation methodsExperience extracting and manipulating large datasets\n",
      "\n",
      "【Real Result】| predictive modeling | machine learning \n",
      "【Extract Result】| predictive modeling | machine learning | experimentation methodsExperience extracting \n",
      "========================================================================================================================\n",
      "Extensive R and Python / Django experience\n",
      "\n",
      "【Real Result】| R | Python | Django \n",
      "【Extract Result】| Python | Django \n",
      "========================================================================================================================\n",
      "We are seeking a senior - level Data Scientist to join our team .\n",
      "\n",
      "【Real Result】| Data Scientist \n",
      "【Extract Result】| Data Scientist \n",
      "========================================================================================================================\n",
      "5 + years of practical experience with a BS or MS or PhD in Mathematics , Economics , Computer Science , Information Management or Statistics\n",
      "\n",
      "【Real Result】| BS | MS | PhD | Mathematics | Economics | Computer Science | Information Management | Statistics \n",
      "【Extract Result】| BS | MS | PhD | Mathematics | Economics | Computer Science | Information Management | Statistics \n",
      "========================================================================================================================\n",
      "Experience conducting original research using data science techniques , including machine learning , deep learning , statistical modeling , and data visualization\n",
      "\n",
      "【Real Result】| original research | data science | machine learning | deep learning | statistical modeling | data visualization \n",
      "【Extract Result】| original research | data science techniques | machine learning | deep learning | statistical modeling | data visualization \n",
      "========================================================================================================================\n",
      "Knowledge of Cloud Computing technologies , particularly in the AWS environment\n",
      "\n",
      "【Real Result】| Cloud Computing technologies | AWS \n",
      "【Extract Result】| Cloud Computing | AWS \n",
      "========================================================================================================================\n",
      "You will employ your mathematical science , computer science , and quantitative analysis skills to ensure solutions to complex data problems and take full advantage of the NSA 's software and hardware capabilities in all areas of our enterprise , including analytic capabilities , research , and foreign intelligence operations .\n",
      "\n",
      "【Real Result】| mathematical science | computer science | quantitative analysis | analytic capabilities | research \n",
      "【Extract Result】| mathematical science | computer science | quantitative analysis problems | research \n",
      "========================================================================================================================\n",
      "Strong communication and data presentation skills\n",
      "\n",
      "【Real Result】| data presentation skills \n",
      "【Extract Result】| communication and | data presentation skills \n",
      "========================================================================================================================\n",
      "As an ML Solutions Lab data scientist , you are proficient in designing and developing advanced ML models to solve diverse challenges and opportunities .\n",
      "\n",
      "【Real Result】| ML \n",
      "【Extract Result】| ML data scientist | ML models \n",
      "========================================================================================================================\n",
      "Expert level coding skills ( Python , R , Scala , SQL , etc ) , and experience developing in a Unix environment .\n",
      "\n",
      "【Real Result】| Python | R | Scala | SQL | Unix \n",
      "【Extract Result】| coding skills | Python | R | Scala | SQL | Unix environment \n",
      "========================================================================================================================\n",
      "Analyze data using advanced analytics techniques in support of process improvement efforts using modern analytics frameworks , including – but not limited to – Python , R , Scala , or equivalent ; Spark , Hadoop file system and others .\n",
      "\n",
      "【Real Result】| advanced analytics | Python | R | Scala | Spark | Hadoop \n",
      "【Extract Result】analytics | analytics frameworks | Python | R | Scala | Spark | Hadoop file system \n",
      "========================================================================================================================\n",
      "Experience visualizing / presenting data for stakeholders using : Periscope , Business Objects , D3 , ggplot , etc .\n",
      "\n",
      "【Real Result】| visualizing / presenting data | Periscope | D3 | ggplot \n",
      "【Extract Result】| visualizing | Periscope | Business Objects | D3 | ggplot \n",
      "========================================================================================================================\n",
      "Our proprietary platform harnesses machine learning algorithms to enable marketing and sales teams to seamlessly coordinate and optimize multichannel engagement with HCPs .\n",
      "\n",
      "【Real Result】| machine learning \n",
      "【Extract Result】machine learning | marketing | optimize | HCPs \n",
      "========================================================================================================================\n",
      "The Cognitive / Machine Learning Professional 2 work assignments are varied and frequently require interpretation and independent determination of the appropriate courses of action .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| Cognitive | Machine Learning \n",
      "【Extract Result】| Cognitive Machine Learning \n",
      "========================================================================================================================\n",
      "Demonstrated experience with SAS , QlikView , SQL , PL / SQL , MATLAB or similar statistical tools\n",
      "\n",
      "【Real Result】| SAS | QlikView | SQL | PL / SQL | MATLAB \n",
      "【Extract Result】| QlikView | SQL | PL / SQL | MATLAB | statistical tools \n",
      "========================================================================================================================\n",
      "Software programming proficiency with Java , C , R , Python , and/or MATLAB\n",
      "\n",
      "【Real Result】| Java | C | R | Python | MATLAB \n",
      "【Extract Result】programming proficiency | Java | C | R | Python | and/or MATLAB \n",
      "========================================================================================================================\n",
      "We are seeking a Data Scientist to assist in analyzing and implementing data driven solutions to problems specific to risk analysis projects and programs .\n",
      "\n",
      "【Real Result】| Data Scientist | risk analysis \n",
      "【Extract Result】| Data Scientist | analyzing \n",
      "========================================================================================================================\n",
      "As this Data Scientist , you will use established programmatic and quantitative methods to find patterns and relationships in large data sets .\n",
      "\n",
      "【Real Result】| quantitative methods | find patterns \n",
      "【Extract Result】| Data Scientist | programmatic quantitative methods \n",
      "========================================================================================================================\n",
      "MS degree in Electrical Engineering , Computer Engineering , or Computer Science ; and at least 6 years of related experience researching and providing data science solutions in the areas of data understanding and insight , big data and cloud computing .\n",
      "\n",
      "【Real Result】| MS degree | Electrical Engineering | Computer Engineering | Computer Science | big data | cloud computing \n",
      "【Extract Result】| Electrical Engineering | Computer Engineering | Computer Science | data science solutions | data | insight | big data | cloud computing \n",
      "========================================================================================================================\n",
      "Excellent communication and presentation skills\n",
      "\n",
      "【Real Result】| communication and presentation skills \n",
      "【Extract Result】| communication and presentation skills \n",
      "========================================================================================================================\n",
      "Perform rapid ad - hoc analysis and present results in a clear manner starting with structured or unstructured datasets\n",
      "\n",
      "【Real Result】| ad - hoc analysis \n",
      "【Extract Result】ad - hoc analysis | structured | unstructured \n",
      "========================================================================================================================\n",
      "A Bachelors , Masters or Doctoral degree in Computer Science , Computational Linguistics , Engineering , Statistics , Machine Learning , or Natural Sciences\n",
      "\n",
      "【Real Result】| Bachelors | Masters | Doctoral degree | Computer Science | Computational Linguistics | Engineering | Statistics | Machine Learning | Natural Sciences \n",
      "【Extract Result】| Bachelors | Masters | Doctoral degree | Computer Science | Computational Linguistics | Engineering | Statistics | Machine Learning | Natural Sciences \n",
      "========================================================================================================================\n",
      "In addition , this role will be responsible for the following : collect , process and cleanse raw data from a wide variety of sources .\n",
      "\n",
      "【Real Result】| collect | process | cleanse \n",
      "【Extract Result】\n",
      "========================================================================================================================\n",
      "Experience with R , Python\n",
      "\n",
      "【Real Result】| R | Python \n",
      "【Extract Result】| R | Python \n",
      "========================================================================================================================\n",
      "Strong experience using machine learning and deep learning packages\n",
      "\n",
      "【Real Result】| machine learning | deep learning \n",
      "【Extract Result】| machine learning | deep learning \n",
      "========================================================================================================================\n",
      "7 + year ’s professional experience working in quantitative computational role\n",
      "\n",
      "【Real Result】| quantitative computational \n",
      "【Extract Result】| quantitative computational role \n",
      "========================================================================================================================\n",
      "Advanced degree in physics , applied mathematics , statistics or related field is preferred\n",
      "\n",
      "【Real Result】| Advanced degree | physics | applied mathematics | statistics \n",
      "【Extract Result】degree physics | applied mathematics | statistics \n",
      "========================================================================================================================\n",
      "Prepare data for modelling and make best / creative use of applicable and available internal or external data\n",
      "\n",
      "【Real Result】| modelling \n",
      "【Extract Result】| modelling \n",
      "========================================================================================================================\n",
      "Strong grounding in machine learning ( ML ) approaches and techniques\n",
      "\n",
      "【Real Result】| machine learning | ML \n",
      "【Extract Result】| machine learning | ML \n",
      "========================================================================================================================\n",
      "Natural language processing\n",
      "\n",
      "【Real Result】| Natural language processing \n",
      "【Extract Result】| language processing \n",
      "========================================================================================================================\n",
      "Strong SQL skills , and experience coding with Python ( or R )\n",
      "\n",
      "【Real Result】| SQL | Python | R \n",
      "【Extract Result】| SQL skills | Python | R \n",
      "========================================================================================================================\n",
      "5 + years of experience as a Data Scientist , preferably in Big Data Environment\n",
      "\n",
      "【Real Result】| Data Scientist | Big Data Environment \n",
      "【Extract Result】| Data Scientist | preferably | Big Data Environment \n",
      "========================================================================================================================\n",
      "Experience with the Atlassian suite of tools ( Confluence , JIRA ) and GitLab code repository .\n",
      "\n",
      "【Real Result】| Atlassian suite | Confluence | JIRA | GitLab \n",
      "【Extract Result】| tools | Confluence | JIRA | GitLab \n",
      "========================================================================================================================\n",
      "Supports the generation of an automated insights generation framework for business partners to effectively interpret data Provides actionable insights through data science on Personalization , Search & Navigation , SEO & Promotions , Supply Chain , Services , other company priorities , etc .\n",
      "\n",
      "【Real Result】| Personalization | Search | Navigation | SEO | Promotions | Supply Chain | Services \n",
      "【Extract Result】| data science | Personalization | Search & | Navigation | SEO & Promotions | Supply Chain | company priorities \n",
      "========================================================================================================================\n",
      "Should have hands on experience in applying SVM , Neural Nets , Random Forest , K - means clustering , Nearest neighbor , CHAID , CART etc .\n",
      "\n",
      "【Real Result】| SVM | Neural Nets | Random Forest | K - means clustering | Nearest neighbor | CHAID | CART \n",
      "【Extract Result】| SVM | Neural Nets | Random Forest | K - means | clustering | neighbor | CHAID | CART \n",
      "========================================================================================================================\n",
      "Experience in Object Oriented Programming ( OOP ) Languages\n",
      "\n",
      "【Real Result】| Object Oriented Programming | OOP \n",
      "【Extract Result】| Object Oriented Programming | OOP \n",
      "========================================================================================================================\n",
      "Expert working within enterprise data warehouse environments platforms ( Teradata , Netezza , Oracle , etc . ) and working within distributed computing platforms such as Hadoop and associated technologies such as SQL , HQL , MapReduce , Spark , Storm , Yarn , Kafka , Sqoop and Hive .\n",
      "\n",
      "【Real Result】| data warehouse | Teradata | Netezza | Oracle | distributed computing platforms | Hadoop | SQL | HQL | MapReduce | Spark | Storm | Yarn | Kafka | Sqoop | Hive \n",
      "【Extract Result】| enterprise data warehouse environments platforms | Teradata | Netezza | Oracle | distributed computing platforms | Hadoop | SQL | HQL | MapReduce | Spark | Storm | Yarn | Kafka | Sqoop \n",
      "========================================================================================================================\n",
      "Experience with software development , either an open - source enterprise software development stack ( Java / Linux / Ruby / Python ) or a Windows development stack ( .NET , C # , C++ ) .\n",
      "\n",
      "【Real Result】| software development | Java | Linux | Ruby | Python | .NET | C # | C++ \n",
      "【Extract Result】| software development enterprise software development stack | Java | Linux | Ruby / | Python | Windows development stack | .NET # | C++ \n",
      "========================================================================================================================\n",
      "Real world experience using Hadoop and the related query engines ( Hive / Impala )\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| Hadoop | query engines | Hive | Impala \n",
      "【Extract Result】| Hadoop | query engines | Hive / | Impala \n",
      "========================================================================================================================\n",
      "Proficiency in designing & solving classification / prediction problems using open source libraries such as Scikit learn .\n",
      "\n",
      "【Real Result】| classification | prediction | Scikit learn \n",
      "【Extract Result】| classification | prediction problems source | Scikit \n",
      "========================================================================================================================\n",
      "Deep understanding of and experience of modern machine learning techniques such as classification , recommendation systems , and other shallow learning techniques , data analytics , and statistical models .\n",
      "\n",
      "【Real Result】| modern machine learning techniques | classification | recommendation systems | data analytics | statistical models \n",
      "【Extract Result】| machine learning techniques | classification | recommendation systems | shallow learning techniques | data analytics | statistical models \n",
      "========================================================================================================================\n",
      "You 'll have an opportunity to interact directly with our Product , Design , and Business leadership teams to surface critical topics , identify innovative practices , and develop high - impact solutions that advance the state - of - the - art in User Experience research .\n",
      "\n",
      "【Real Result】| User Experience research \n",
      "【Extract Result】| Design \n",
      "========================================================================================================================\n",
      "Experience with Apache Spark Natural Language Processing ( tokenization , tagging , sentiment analysis , entity recognition , summarization )\n",
      "\n",
      "【Real Result】| Apache Spark | Natural Language Processing | tokenization | tagging | sentiment analysis | entity recognition | summarization \n",
      "【Extract Result】| Apache Spark Natural Language Processing | tokenization | tagging | sentiment analysis | entity recognition | summarization \n",
      "========================================================================================================================\n",
      "Knowledge of statistics including hypothesis testing\n",
      "\n",
      "【Real Result】| statistics | hypothesis testing \n",
      "【Extract Result】| statistics | hypothesis testing \n",
      "========================================================================================================================\n",
      "problem scoping , data gathering , EDA , modelling , insights , and visualizations\n",
      "\n",
      "【Real Result】| problem scoping | data gathering | EDA | modelling | insights | visualizations \n",
      "【Extract Result】| problem scoping | data gathering | EDA | modelling | insights | visualizations \n",
      "========================================================================================================================\n",
      "Graduate degree in Data Science or Data Analytics or a related quantitative field .\n",
      "\n",
      "【Real Result】| Data Science | Data Analytics | quantitative field \n",
      "【Extract Result】| Data Science | Data Analytics | quantitative \n",
      "========================================================================================================================\n",
      "Help improve the scope our data sets by identifying new data collection and procurement opportunities on an ongoing basis Drive A / B , multivariate tests and design of experiments to facilitate testing of new product and design features , with a focus on improving engagement , retention , and conversion .\n",
      "\n",
      "【Real Result】| A / B , multivariate tests | design features \n",
      "【Extract Result】collection | multivariate tests | design | retention \n",
      "========================================================================================================================\n",
      "5 - 7 years of experience in developing and implementing advanced machine learning or algorithmic solutions in a data rich environment .\n",
      "\n",
      "【Real Result】| machine learning | algorithmic | data rich environment \n",
      "【Extract Result】| machine learning | algorithmic | data rich \n",
      "========================================================================================================================\n",
      "Exposure to different Machine Learning techniques , and\n",
      "\n",
      "【Real Result】| Machine Learning \n",
      "【Extract Result】| Machine Learning \n",
      "========================================================================================================================\n",
      "Experience in quantitative analysis and translation of findings into actionable insights\n",
      "\n",
      "【Real Result】| quantitative analysis \n",
      "【Extract Result】| quantitative analysis | actionable \n",
      "========================================================================================================================\n",
      "Develop and implement databases , data collection systems , data analytics , and other strategies that will provide efficient data and reporting solutions .\n",
      "\n",
      "【Real Result】| databases | data collection systems | data analytics \n",
      "【Extract Result】| databases | data collection systems | data analytics | data | reporting solutions \n",
      "========================================================================================================================\n",
      "Knowledge of at least one modeling framework ( e.g. , SciKit Learn , TensorFlow , SAS , R , MATLAB )\n",
      "\n",
      "【Real Result】| modeling framework | SciKit Learn | TensorFlow | SAS | R | MATLAB \n",
      "【Extract Result】| modeling framework | e.g. | SciKit Learn | TensorFlow | SAS | MATLAB \n",
      "========================================================================================================================\n",
      "Data Science , Math , Statistics or Information Management background\n",
      "\n",
      "【Real Result】| Data Science | Math | Statistics | Information Management \n",
      "【Extract Result】| Data Science | Math | Statistics | Information Management background \n",
      "========================================================================================================================\n",
      "Continually refines and optimizes Machine Learning algorithms .\n",
      "\n",
      "【Real Result】| Machine Learning \n",
      "【Extract Result】| refines | optimizes Machine Learning algorithms \n",
      "========================================================================================================================\n",
      "Data Mining , Machine Learning , Optimization Predictive and Prescriptive Analytics\n",
      "\n",
      "【Real Result】| Data Mining | Machine Learning | Optimization Predictive and Prescriptive Analytics \n",
      "【Extract Result】| Data Mining | Machine Learning | Optimization Predictive | Prescriptive Analytics \n",
      "========================================================================================================================\n",
      "Lead Data Scientist works with business partners around the enterprise to lead the design , development , and implementation of analytics / machine learning solutions that drive measurable business outcomes and create a distinctive customer experience .\n",
      "\n",
      "【Real Result】| design | development | implementation | analytics / machine learning \n",
      "【Extract Result】Scientist | analytics | machine learning \n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "indeX = 0\n",
    "for tem in test_x:\n",
    "    print( ' '.join(tem) )\n",
    "    print()\n",
    "    print( '【Real Result】' ,end='' )\n",
    "    for i in range( len( tem ) ):\n",
    "        if test_y[indeX][i] == 'B':\n",
    "            print( '|',tem[i],'',end='' )\n",
    "            \n",
    "        if test_y[indeX][i] == 'I':\n",
    "            print( tem[i],'',end='' )\n",
    "            \n",
    "    print_predict( model, tem  )\n",
    "    \n",
    "    indeX +=1 \n",
    "    print( '=' * 120 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input a random JD output Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en_core_web_sm'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process( model, tem ):\n",
    "    temp_list = []\n",
    "    predict_list = model.ModelPredict( [w.lower() for w in tem] )\n",
    "            \n",
    "    for index in range(0,len(predict_list)):\n",
    "        if predict_list[index] == 'B' or predict_list[index] == 'I':\n",
    "            temp_list.append(  \"<span style='background:yellow'>\"+str(tem[index])+'</span>' )\n",
    "            \n",
    "        else:\n",
    "            temp_list.append( str(tem[index]) )\n",
    "        \n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Query</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>388</td>\n",
       "      <td>388</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;P&gt;&lt;STRONG&gt;As a member of the Web and Portal D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;BR&gt;\\r&lt;TABLE border=0 cellSpacing=0 cellPaddin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;strong&gt;Application Developer-Senior-Java&lt;br&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4631</td>\n",
       "      <td>4631</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;b&gt;Responsibilities:&lt;/b&gt; Kforce is seeking a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>4873</td>\n",
       "      <td>4873</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;b&gt;Responsibilities:&lt;/b&gt; Our client is looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71866</th>\n",
       "      <td>1114580</td>\n",
       "      <td>1114580</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Energize Global Services CJSC is looking for J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71871</th>\n",
       "      <td>1114616</td>\n",
       "      <td>1114616</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Workfront is a technology company that needs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71875</th>\n",
       "      <td>1114710</td>\n",
       "      <td>1114710</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>EPAM Systems, Inc. is seeking Java Developers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71889</th>\n",
       "      <td>1114949</td>\n",
       "      <td>1114949</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Monitis is looking for a Java Developer who wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71895</th>\n",
       "      <td>1115103</td>\n",
       "      <td>1115103</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>NASDAQ OMX Armenia is seeking an energetic Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1796 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1           Query  \\\n",
       "6             388           388  Java Developer   \n",
       "7             395           395  Java Developer   \n",
       "11            713           713  Java Developer   \n",
       "118          4631          4631  Java Developer   \n",
       "132          4873          4873  Java Developer   \n",
       "...           ...           ...             ...   \n",
       "71866     1114580       1114580  Java Developer   \n",
       "71871     1114616       1114616  Java Developer   \n",
       "71875     1114710       1114710  Java Developer   \n",
       "71889     1114949       1114949  Java Developer   \n",
       "71895     1115103       1115103  Java Developer   \n",
       "\n",
       "                                             Description  \n",
       "6      <P><STRONG>As a member of the Web and Portal D...  \n",
       "7      <BR>\\r<TABLE border=0 cellSpacing=0 cellPaddin...  \n",
       "11     <strong>Application Developer-Senior-Java<br>\\...  \n",
       "118    <b>Responsibilities:</b> Kforce is seeking a m...  \n",
       "132    <b>Responsibilities:</b> Our client is looking...  \n",
       "...                                                  ...  \n",
       "71866  Energize Global Services CJSC is looking for J...  \n",
       "71871  Workfront is a technology company that needs a...  \n",
       "71875  EPAM Systems, Inc. is seeking Java Developers ...  \n",
       "71889  Monitis is looking for a Java Developer who wi...  \n",
       "71895  NASDAQ OMX Armenia is seeking an energetic Jav...  \n",
       "\n",
       "[1796 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JD_DF = pd.read_csv(r'../Data/JD.csv')\n",
    "JD_DF = JD_DF[JD_DF['Query'] == 'Java Developer']\n",
    "JD_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get a random JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking to identify at least 5 more developers for an Army Contract in Springfield, VA.  Many of the requirements below are ideal but if you don't possess all of them training will be provided on the job.  Must be able to obtain a DOD Secret Clearance.  \n",
      "\n",
      "\n",
      "Position Description \n",
      "Designs, develops, and implements web-based Java applications to support business requirements. Follows approved life cycle methodologies, creates design documents, and performs program coding and testing. Resolves technical issues through troubleshooting, debugging, research, and investigation.  Familiar with software development concepts, practices, and procedures (i.e. Java, EJB 3.0, JSP, JSF, HTML, SQL, Javascript). Relies on extensive experience and judgment to plan and accomplish goals.  \n",
      "Principle Duties and Responsibilities:\n",
      "\n",
      "    Experience in building enterprise software or large scale web application required\n",
      "    Strong Java and J EE software development required\n",
      "    Experience in servlets and JSP development required\n",
      "    Hands-on experience with EJB3 or ORM software (hibernate, toplink, JDO, etc) required\n",
      "    Ability to work across all layers of the application, from back-end databases through to the user interface\n",
      "    In-depth knowledge with relational database, such SQL Server or Oracle, is required\n",
      "    Agile/Iterative development methodology\n",
      "    SQL; AJAX; JBoss; Jasper Reports\n",
      "    Working knowledge of database relational design, data normalization and experience with JDBC drivers\n",
      "    Experience in JavaServer Faces (JSF) is highly desirable\n",
      "    Experience working on high scalable, distributed, high transaction applications is a plus\n",
      "    Experience with creating web services or implementing client portion of web service is desirable\n",
      "    Experience in Software as a Service (SaaS) is a plus\n",
      "    Knowledge of design patterns is a plus\n",
      "    Experience in JavaScript is a plus.\n",
      "\n",
      "Job Specifications:\n",
      "\n",
      "    A bachelors degree in Computer Science or Engineering and at least 6 years of Java experience working with server side applications, 7 years of experience can be substituted for a degree\n",
      "    Candidates must be clearable US Citizens or hold at least an interim DOD security clearance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = JD_DF.sample(1).iloc[0]['Description']\n",
    "soup = BeautifulSoup(text)\n",
    "text = soup.get_text()\n",
    "\n",
    "for sentence in text.replace('\\\\r','\\\\n').split('\\\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output the NER result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>We are looking to identify at least 5 more developers for an Army Contract in Springfield , VA .    Many of the requirements below are ideal but if you do n't possess all of them training will be provided on the job .    Must be able to obtain a DOD Secret Clearance .    <br> <br> <br> Position <span style='background:yellow'>Description</span> <span style='background:yellow'><br></span> Designs , <span style='background:yellow'>develops</span> , and implements <span style='background:yellow'>web</span> <span style='background:yellow'>-</span> <span style='background:yellow'>based</span> <span style='background:yellow'>Java</span> <span style='background:yellow'>applications</span> to support business requirements . Follows approved life cycle <span style='background:yellow'>methodologies</span> , creates <span style='background:yellow'>design</span> <span style='background:yellow'>documents</span> , and performs program <span style='background:yellow'>coding</span> and <span style='background:yellow'>testing</span> . Resolves technical issues through <span style='background:yellow'>troubleshooting</span> , <span style='background:yellow'>debugging</span> , <span style='background:yellow'>research</span> , and investigation .    Familiar with software development concepts , practices , and <span style='background:yellow'>procedures</span> ( <span style='background:yellow'>i.e.</span> <span style='background:yellow'>Java</span> , <span style='background:yellow'>EJB</span> <span style='background:yellow'>3.0</span> , <span style='background:yellow'>JSP</span> , <span style='background:yellow'>JSF</span> , <span style='background:yellow'>HTML</span> , <span style='background:yellow'>SQL</span> , <span style='background:yellow'>Javascript</span> ) . Relies on extensive experience and judgment to plan and accomplish goals . <span style='background:yellow'>  </span> <br> Principle Duties and Responsibilities : <span style='background:yellow'><br></span> <br>      Experience in building <span style='background:yellow'>enterprise</span> <span style='background:yellow'>software</span> or large scale <span style='background:yellow'>web</span> application required <br>      Strong <span style='background:yellow'>Java</span> and J EE software development required <br>      Experience in <span style='background:yellow'>servlets</span> and <span style='background:yellow'>JSP</span> development required <span style='background:yellow'><br></span>      Hands - on experience with <span style='background:yellow'>EJB3</span> or <span style='background:yellow'>ORM</span> <span style='background:yellow'>software</span> ( <span style='background:yellow'>hibernate</span> , <span style='background:yellow'>toplink</span> , <span style='background:yellow'>JDO</span> , etc ) required <span style='background:yellow'><br></span>      Ability to work across all layers of the application , from back - end databases through to the user interface <br>      In - depth knowledge with <span style='background:yellow'>relational</span> <span style='background:yellow'>database</span> , such <span style='background:yellow'>SQL</span> <span style='background:yellow'>Server</span> or <span style='background:yellow'>Oracle</span> , is required <span style='background:yellow'><br></span>      Agile / <span style='background:yellow'>Iterative</span> development methodology <span style='background:yellow'><br></span>      <span style='background:yellow'>SQL</span> ; <span style='background:yellow'>AJAX</span> ; <span style='background:yellow'>JBoss</span> ; <span style='background:yellow'>Jasper</span> <span style='background:yellow'>Reports</span> <span style='background:yellow'><br></span>      Working knowledge of <span style='background:yellow'>database</span> <span style='background:yellow'>relational</span> <span style='background:yellow'>design</span> , <span style='background:yellow'>data</span> <span style='background:yellow'>normalization</span> and experience with <span style='background:yellow'>JDBC</span> drivers <br>      Experience in <span style='background:yellow'>JavaServer</span> Faces ( <span style='background:yellow'>JSF</span> ) is highly desirable <span style='background:yellow'><br></span>      Experience working on high <span style='background:yellow'>scalable</span> , <span style='background:yellow'>distributed</span> , <span style='background:yellow'>high</span> <span style='background:yellow'>transaction</span> <span style='background:yellow'>applications</span> is a plus <span style='background:yellow'><br></span>      Experience with creating <span style='background:yellow'>web</span> services or implementing client portion of <span style='background:yellow'>web</span> service is desirable <br>      Experience in <span style='background:yellow'>Software</span> as a <span style='background:yellow'>Service</span> ( <span style='background:yellow'>SaaS</span> ) is a plus <span style='background:yellow'><br></span>      Knowledge of <span style='background:yellow'>design</span> <span style='background:yellow'>patterns</span> is a plus <span style='background:yellow'><br></span>      Experience in <span style='background:yellow'>JavaScript</span> is a plus . <span style='background:yellow'><br></span> <br> Job Specifications : <span style='background:yellow'><br></span> <br>      A <span style='background:yellow'>bachelors</span> <span style='background:yellow'>degree</span> in <span style='background:yellow'>Computer</span> <span style='background:yellow'>Science</span> or <span style='background:yellow'>Engineering</span> and at least 6 years of <span style='background:yellow'>Java</span> experience working with server side applications , 7 years of experience can be substituted for a <span style='background:yellow'>degree</span> <span style='background:yellow'><br></span>      Candidates must be clearable US Citizens or hold at least an interim DOD security clearance <br> <br></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [sentence for sentence in text.replace('\\\\t',' ').replace('\\\\r','\\\\n').split('\\\\n')]\n",
    "\n",
    "total_text_list = []\n",
    "for sent in sentences:\n",
    "#     sentence = str(sent).replace('\\r',' ').replace('\\\\r',' ').replace('\\\\n',' ').replace('\\n',' ').replace('\\t',' ').replace('\\\\t',' ')\n",
    "#     sentence = sentence.strip(' ')\n",
    "    \n",
    "    total_text_list += process( model, [str(w) for w in list(nlp(sent))[:120] ] +['<br>'] )\n",
    "#     print( '-' * 120 )\n",
    "\n",
    "display(HTML( '<html>'+' '.join(total_text_list) + '</html>' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
