{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"NER_dataset/tran_X.json\", \"r\") as f:\n",
    "    X = json.load(f)\n",
    "    \n",
    "with open(\"NER_dataset/tran_Y.json\", \"r\") as f:\n",
    "    Y = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buliding training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "for ind in range(len(X)):\n",
    "    if ind % 7 == 0:\n",
    "        test_x.append( X[ind] )\n",
    "        test_y.append( Y[ind] )\n",
    "\n",
    "    else:\n",
    "        train_x.append( X[ind] )\n",
    "        train_y.append( Y[ind] )\n",
    "\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x for x in train_x if len(x) > 2 and len(x) < 120]\n",
    "train_y = [x for x in train_y if len(x) > 2 and len(x) < 120]\n",
    "\n",
    "test_x = [x for x in test_x if len(x) > 2 and len(x) < 120]\n",
    "test_y = [x for x in test_y if len(x) > 2 and len(x) < 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:\n",
      "['Experience', 'working', 'on', 'front', '-', 'back', '-', 'end', ',', 'or', 'full', '-', 'stack', 'web', 'development', 'projects', '.']\n",
      "label:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print('sentence:')\n",
    "print( train_x[0] )\n",
    "print('label:')\n",
    "print( train_y[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset_size: 525\n",
      "testset_size: 88\n"
     ]
    }
   ],
   "source": [
    "print( 'trainset_size:',len( train_x ) )\n",
    "print( 'testset_size:',len( test_x ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import Tokenizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_bilstm_crf:\n",
    "    def __init__(self, max_seq_length, batch_size, epochs, lstm_dim):\n",
    "        self.label = {}\n",
    "        self._label = {}\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lstmDim = lstm_dim\n",
    "        self.LoadLabel()\n",
    "        self.model = self.Model()\n",
    "\n",
    "    ##############################################\n",
    "    def LoadLabel(self):\n",
    "        #label\n",
    "        label_path = r\"uncased_L-2_H-128_A-2/tag_dict.txt\"\n",
    "        f_label = open(label_path, 'r+', encoding='utf-8')\n",
    "        for line in f_label:\n",
    "            content = line.strip().split()\n",
    "            self.label[content[0].strip()] = content[1].strip()\n",
    "            self._label[content[1].strip()] = content[0].strip()\n",
    "            \n",
    "        #dict\n",
    "        self.vocab = {}\n",
    "        vocab_path = r\"uncased_L-2_H-128_A-2/vocab.txt\"\n",
    "        with open(vocab_path, 'r+', encoding='utf-8') as f_vocab:\n",
    "            for line in f_vocab.readlines():\n",
    "                self.vocab[line.strip()] = len(self.vocab)\n",
    "\n",
    "    def Model(self):\n",
    "        model_path = r\"uncased_L-2_H-128_A-2/\"\n",
    "        bert = load_trained_model_from_checkpoint(\n",
    "            model_path + \"bert_config.json\",\n",
    "            model_path + \"bert_model.ckpt\",\n",
    "            seq_len=self.max_seq_length\n",
    "            )\n",
    "        #make bert layer trainable\n",
    "        for layer in bert.layers:\n",
    "            layer.trainable = True\n",
    "        x1 = Input(shape=(None,))\n",
    "        x2 = Input(shape=(None,))\n",
    "        bert_out = bert([x1, x2])\n",
    "        lstm_out = Bidirectional(LSTM(self.lstmDim,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2,\n",
    "                                         recurrent_dropout=0.2))(bert_out)\n",
    "        crf_out = CRF(len(self.label), sparse_target=True)(lstm_out)\n",
    "        model = Model([x1, x2], crf_out)\n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(1e-4),\n",
    "            loss=crf_loss,\n",
    "            metrics=[crf_accuracy]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def PreProcessInputData(self, text):\n",
    "        word_labels = []\n",
    "        seq_types = []\n",
    "        \n",
    "        for sequence in text:\n",
    "            len_text = len(sequence)\n",
    "            \n",
    "            ###########################################\n",
    "            temp_word_labels = []\n",
    "            \n",
    "            temp_word_labels.append( 101 )            \n",
    "            for w in sequence:\n",
    "                temp_word_labels.append( self.vocab.get(w,1) )\n",
    "            temp_word_labels.append( 102 )\n",
    "            \n",
    "            ###########################################\n",
    "            temp_seq_types = [1] * len(temp_word_labels) +  [0] * (self.max_seq_length - len( temp_word_labels ))\n",
    "            temp_word_labels = temp_word_labels + [0] * (self.max_seq_length - len( temp_word_labels ))\n",
    "            \n",
    "            word_labels.append( temp_word_labels )\n",
    "            seq_types.append( temp_seq_types )\n",
    "            \n",
    "        return word_labels, seq_types\n",
    "\n",
    "\n",
    "    def PreProcessOutputData(self, text):\n",
    "        tags = []\n",
    "        for line in text:\n",
    "            tag = [0]\n",
    "            for item in line:\n",
    "                tag.append(int(self.label[item.strip()]))\n",
    "            tag.append(0)\n",
    "            tags.append(tag)\n",
    "\n",
    "        pad_tags = pad_sequences(tags, maxlen=self.max_seq_length, padding=\"post\", truncating=\"post\")\n",
    "        result_tags = np.expand_dims(pad_tags, 2)\n",
    "        return result_tags\n",
    "\n",
    "    def TrainModel(self, train_data):\n",
    "        input_train, result_train = train_data\n",
    "        input_test, result_test = test_data\n",
    "        \n",
    "        #训练集\n",
    "        input_train_labels, input_train_types = self.PreProcessInputData(input_train)\n",
    "        result_train = self.PreProcessOutputData(result_train)\n",
    "        \n",
    "        #测试集\n",
    "#         input_test_labels, input_test_types = self.PreProcessInputData(input_test)\n",
    "#         result_test = self.PreProcessOutputData(result_test)\n",
    "        \n",
    "        history = self.model.fit(x=[input_train_labels, input_train_types],\n",
    "                       y=result_train,\n",
    "                       validation_split=0.2,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       shuffle=True,\n",
    "                       verbose=1,\n",
    "                       class_weight = 'auto')\n",
    "        \n",
    "        self.model.save('NER_model/my_NER_model')\n",
    "        return\n",
    "\n",
    "    def Id2Label(self, ids):\n",
    "        result = []\n",
    "        for id in ids:\n",
    "            result.append(self._label[str(id)])\n",
    "        return result\n",
    "\n",
    "    def Vector2Id(self, tags):\n",
    "        result = []\n",
    "        for tag in tags:\n",
    "            result.append(np.argmax(tag))\n",
    "        return result\n",
    "\n",
    "    def ModelPredict(self, sentence):\n",
    "        labels, types = self.PreProcessInputData([sentence])\n",
    "        self.model.load_weights('NER_model/my_NER_model')\n",
    "        tags = self.model.predict([labels, types])[0]\n",
    "        \n",
    "        result = []\n",
    "        for i in range(1, len(sentence) + 1):\n",
    "            result.append(tags[i])\n",
    "        result = self.Vector2Id(result)\n",
    "        tag = self.Id2Label(result)\n",
    "        return tag\n",
    "\n",
    "    def EvalModel(self, valid_data):\n",
    "        input_valid, result_valid = valid_data\n",
    "        #训练集\n",
    "        input_valid_labels, input_valid_types = self.PreProcessInputData(input_valid)\n",
    "        result_valid = self.PreProcessOutputData(result_valid)\n",
    "        \n",
    "        res = ( self.model.evaluate(x=[input_valid_labels, input_valid_types],\n",
    "                           y=result_valid,batch_size=self.batch_size) )\n",
    "        print(res)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             4320256     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 128)    98816       model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "crf_1 (CRF)                     (None, None, 5)      680         bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 4,419,752\n",
      "Trainable params: 4,419,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lothar/conda/envs/my_TF_CPU_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 420 samples, validate on 105 samples\n",
      "Epoch 1/20\n",
      "420/420 [==============================] - 26s 63ms/step - loss: 12.0040 - crf_accuracy: 0.7179 - val_loss: 11.2241 - val_crf_accuracy: 0.6848\n",
      "Epoch 2/20\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 11.7557 - crf_accuracy: 0.7511 - val_loss: 10.9852 - val_crf_accuracy: 0.7597\n",
      "Epoch 3/20\n",
      "420/420 [==============================] - 16s 38ms/step - loss: 11.5988 - crf_accuracy: 0.8020 - val_loss: 10.8952 - val_crf_accuracy: 0.8121\n",
      "Epoch 4/20\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 11.5159 - crf_accuracy: 0.8361 - val_loss: 10.8294 - val_crf_accuracy: 0.8426\n",
      "Epoch 5/20\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 11.4525 - crf_accuracy: 0.8654 - val_loss: 10.7887 - val_crf_accuracy: 0.8572\n",
      "Epoch 6/20\n",
      "420/420 [==============================] - 21s 50ms/step - loss: 11.4047 - crf_accuracy: 0.8837 - val_loss: 10.7734 - val_crf_accuracy: 0.8675\n",
      "Epoch 7/20\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 11.3705 - crf_accuracy: 0.8959 - val_loss: 10.7572 - val_crf_accuracy: 0.8742\n",
      "Epoch 8/20\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 11.3500 - crf_accuracy: 0.9017 - val_loss: 10.7561 - val_crf_accuracy: 0.8777\n",
      "Epoch 9/20\n",
      "420/420 [==============================] - 19s 44ms/step - loss: 11.3263 - crf_accuracy: 0.9134 - val_loss: 10.7636 - val_crf_accuracy: 0.8839\n",
      "Epoch 10/20\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 11.3113 - crf_accuracy: 0.9172 - val_loss: 10.7487 - val_crf_accuracy: 0.8806\n",
      "Epoch 11/20\n",
      "420/420 [==============================] - 24s 57ms/step - loss: 11.2985 - crf_accuracy: 0.9185 - val_loss: 10.7527 - val_crf_accuracy: 0.8884\n",
      "Epoch 12/20\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 11.2810 - crf_accuracy: 0.9249 - val_loss: 10.7601 - val_crf_accuracy: 0.8912\n",
      "Epoch 13/20\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 11.2747 - crf_accuracy: 0.9273 - val_loss: 10.7461 - val_crf_accuracy: 0.8899\n",
      "Epoch 14/20\n",
      "420/420 [==============================] - 18s 42ms/step - loss: 11.2607 - crf_accuracy: 0.9319 - val_loss: 10.7635 - val_crf_accuracy: 0.8843\n",
      "Epoch 15/20\n",
      "420/420 [==============================] - 23s 54ms/step - loss: 11.2490 - crf_accuracy: 0.9375 - val_loss: 10.7522 - val_crf_accuracy: 0.8895\n",
      "Epoch 16/20\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 11.2379 - crf_accuracy: 0.9374 - val_loss: 10.7794 - val_crf_accuracy: 0.8930\n",
      "Epoch 17/20\n",
      "420/420 [==============================] - 17s 42ms/step - loss: 11.2288 - crf_accuracy: 0.9416 - val_loss: 10.7699 - val_crf_accuracy: 0.8930\n",
      "Epoch 18/20\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 11.2156 - crf_accuracy: 0.9486 - val_loss: 10.7767 - val_crf_accuracy: 0.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "420/420 [==============================] - 23s 55ms/step - loss: 11.2159 - crf_accuracy: 0.9485 - val_loss: 10.7685 - val_crf_accuracy: 0.8846\n",
      "Epoch 20/20\n",
      "420/420 [==============================] - 22s 52ms/step - loss: 11.2042 - crf_accuracy: 0.9543 - val_loss: 10.7836 - val_crf_accuracy: 0.8867\n"
     ]
    }
   ],
   "source": [
    "train_data = ( train_x, train_y )\n",
    "test_data  = ( test_x, test_y )\n",
    "\n",
    "#模型\n",
    "max_seq_length = 128\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lstmDim = 64\n",
    "model = bert_bilstm_crf( max_seq_length, batch_size, epochs, lstmDim )\n",
    "model.TrainModel( train_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predict( model, tem):\n",
    "    predict_list = model.ModelPredict( [w.lower() for w in tem] )\n",
    "\n",
    "    print()\n",
    "    print( '【Extract Result】', end='' )\n",
    "    i = 0\n",
    "    for i in range( len( predict_list ) ):\n",
    "        if predict_list[i] == 'B':\n",
    "            print( '|',tem[i],'',end='' )\n",
    "            \n",
    "        if predict_list[i] == 'I':\n",
    "            print( tem[i],'',end='' )\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience in commonly used for data analysis such as Python , R , Julia , or SAS .\n",
      "\n",
      "【Real Result】| data analysis | Python | R | Julia | SAS \n",
      "【Extract Result】| data analysis | Python | R | Julia | SAS \n",
      "========================================================================================================================\n",
      "Design solutions by mapping client business processes and challenges to an end - to - end solution on the platform utilizing data analytics , machine learning , and artificial intelligence to predict outcomes and prescribe actions\n",
      "\n",
      "【Real Result】| data analytics | machine learning | artificial intelligence \n",
      "【Extract Result】| data analytics | machine learning | artificial intelligence \n",
      "========================================================================================================================\n",
      "Research and keep track of industry trends in Data Analytics / Statistic Modeling / Predictive Modeling / AI / Algorithms to ensure that the department is evaluating new techniques .\n",
      "\n",
      "【Real Result】| Data Analytics | Statistic Modeling | Predictive Modeling | AI | Algorithms \n",
      "【Extract Result】| Data Analytics | Statistic | Modeling / | Predictive Modeling AI Algorithms \n",
      "========================================================================================================================\n",
      "Data Science experience   should have experience in Hadoop , Spark & Hive Building models for highly imbalanced data sets\n",
      "\n",
      "【Real Result】| Hadoop | Spark | Hive \n",
      "【Extract Result】Science | Hadoop | Spark | Hive \n",
      "========================================================================================================================\n",
      "Graduate degree in analytically driven fields such as mathematics , statistics , physics , economics , data science , computer science , operations research or actuarial science .\n",
      "\n",
      "【Real Result】| mathematics | statistics | physics | economics | data science | computer science | operations research | actuarial science \n",
      "【Extract Result】| mathematics | statistics | physics | economics | data science | computer science | operations research | actuarial science \n",
      "========================================================================================================================\n",
      "Cognitive and Communications Skill - Highly articulate , built upon an underlying fundamental clarity of thought .\n",
      "\n",
      "【Real Result】| Cognitive and Communications Skill \n",
      "【Extract Result】| Communications Skill - | articulate \n",
      "========================================================================================================================\n",
      "Proficient with Python , R , SQL Server , MongoDB .\n",
      "\n",
      "【Real Result】| Python | R | SQL Server | MongoDB \n",
      "【Extract Result】| Python | R | SQL Server | MongoDB \n",
      "========================================================================================================================\n",
      "The focus of this position is to develop analytical problems and models , discover insights and identify opportunities through use of statistical , algorithmic , mining and visualization techniques .\n",
      "\n",
      "【Real Result】| statistical | algorithmic | mining | visualization \n",
      "【Extract Result】| models | statistical | algorithmic | mining | visualization \n",
      "========================================================================================================================\n",
      "Work with Junior analyst and developers to build our BI and analytics tools .\n",
      "\n",
      "【Real Result】| BI | analytics \n",
      "【Extract Result】analyst analytics tools \n",
      "========================================================================================================================\n",
      "5 + years of experience with data analytics or data science\n",
      "\n",
      "【Real Result】| data analytics | data science \n",
      "【Extract Result】| data analytics | data science \n",
      "========================================================================================================================\n",
      "HTML , CSS , JavaScript , XML , JSON\n",
      "\n",
      "【Real Result】| HTML | CSS | JavaScript | XML | JSON \n",
      "【Extract Result】| CSS | JavaScript | XML | JSON \n",
      "========================================================================================================================\n",
      "Effective communication skills and ability to explain how your insights and recommendations are directly linked to business optimization and opportunity , including presentation of complex analytical concepts to a non - technical audience ( up to senior management levels ) .\n",
      "\n",
      "【Real Result】| communication skills \n",
      "【Extract Result】| communication skills | business optimization concepts | management \n",
      "========================================================================================================================\n",
      "Prior data science experience working with languages like R , Python , or Java Ability to deliver in a fast - paced , self - directed environment Ability to learn new concepts , tools , languages , and models An analytical mindset\n",
      "\n",
      "【Real Result】| R | Python | Java \n",
      "【Extract Result】science | R | Python | Java | fast - paced - directed concepts | tools | languages | analytical mindset \n",
      "========================================================================================================================\n",
      "Excellent written and verbal communication skills Qualifications Education Required Bachelors or better in Mathematics or related field .\n",
      "\n",
      "【Real Result】| written and verbal communication skills | Mathematics \n",
      "【Extract Result】| written and verbal communication skills | Bachelors | Mathematics \n",
      "========================================================================================================================\n",
      "As a senior data scientist in Wells Fargo Enterprise Complaints Data , Analytics , and Reporting ( CDAR )\n",
      "\n",
      "【Real Result】| Complaints Data | Analytics | Reporting | CDAR \n",
      "【Extract Result】scientist Complaints Data | Analytics | Reporting | CDAR \n",
      "========================================================================================================================\n",
      "Experience with Jupyter Notebooks\n",
      "\n",
      "【Real Result】| Jupyter Notebooks \n",
      "【Extract Result】| Jupyter Notebooks \n",
      "========================================================================================================================\n",
      "Use Hive , Scala , Java or Python to utilize Hadoop / Spark to process large - scale datasets\n",
      "\n",
      "【Real Result】| Hive | Scala | Java | Python | Hadoop | Spark \n",
      "【Extract Result】| Hive | Scala | Java | Python | Hadoop \n",
      "========================================================================================================================\n",
      "Bachelor 's degree in Computer Science , Statistics or STEM related field ; Master 's degree preferred\n",
      "\n",
      "【Real Result】| Bachelor 's degree | Computer Science | Statistics | STEM | Master 's degree \n",
      "【Extract Result】| 's degree | Computer Science | Statistics | STEM | Master 's degree \n",
      "========================================================================================================================\n",
      "Apply statistical analysis and visualization techniques to various data , such as hierarchical clustering , T - distributed Stochastic Neighbor Embedding ( t - SNE ) , principal components analysis ( PCA )\n",
      "\n",
      "【Real Result】| statistical analysis | visualization | hierarchical clustering | T - distributed Stochastic Neighbor Embedding | t - SNE | principal components analysis | PCA \n",
      "【Extract Result】| statistical analysis | visualization | data | hierarchical clustering - | distributed Stochastic Neighbor Embedding - SNE | principal components analysis | PCA \n",
      "========================================================================================================================\n",
      "A PhD in Economics , Econometrics , Business , or related field , and 1 + years of experience applying econometric methods in retail .\n",
      "\n",
      "【Real Result】| Economics | Econometrics | Business | econometric methods \n",
      "【Extract Result】| Econometrics | Business | econometric \n",
      "========================================================================================================================\n",
      "Our advanced analytics algorithms and models are becoming a core part of Cummins physical and digital products every day .\n",
      "\n",
      "【Real Result】| analytics algorithms \n",
      "【Extract Result】| advanced analytics algorithms | digital \n",
      "========================================================================================================================\n",
      "Expertise in R or Python\n",
      "\n",
      "【Real Result】| R | Python \n",
      "【Extract Result】| R | Python \n",
      "========================================================================================================================\n",
      "Experience with data acquisition tools ( e.g. SQL , Apache Spark etc . ) , large datasets ( Hadoop ) and data mining\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| data acquisition tools | SQL | Apache Spark | large datasets | Hadoop | data mining \n",
      "【Extract Result】| data acquisition tools SQL | Apache Spark | Hadoop | data mining \n",
      "========================================================================================================================\n",
      "Possess basic understanding of system requirements for the deployment of the latest versions of R and Python and Scripting\n",
      "\n",
      "【Real Result】| R | Python | Scripting \n",
      "【Extract Result】| Python | Scripting \n",
      "========================================================================================================================\n",
      "Develops and validates statistical forecasting models and tools .\n",
      "\n",
      "【Real Result】| statistical forecasting models \n",
      "【Extract Result】| statistical forecasting models \n",
      "========================================================================================================================\n",
      "1 + year experience with Tableau or Power BI\n",
      "\n",
      "【Real Result】| Tableau | Power BI \n",
      "【Extract Result】| Tableau BI \n",
      "========================================================================================================================\n",
      "Develop and deliver advanced statistical and mathematical models to support fact - based decision making within the organization\n",
      "\n",
      "【Real Result】| mathematical models \n",
      "【Extract Result】| advanced | statistical | mathematical models decision \n",
      "========================================================================================================================\n",
      "RDBMS SQL Development .\n",
      "\n",
      "【Real Result】| RDBMS SQL \n",
      "【Extract Result】| SQL Development \n",
      "========================================================================================================================\n",
      "Experience with SQL .\n",
      "\n",
      "【Real Result】| SQL \n",
      "【Extract Result】| SQL \n",
      "========================================================================================================================\n",
      "Local language skills to an advanced level ( spoken and written ) , with complete fluency in English .\n",
      "\n",
      "【Real Result】| English \n",
      "【Extract Result】| language skills | spoken and | written | English \n",
      "========================================================================================================================\n",
      "Working with modern distributed analytics systems , complex data , and challenging requests , you will have the opportunity to apply complex code , and possibly move into a Methodology role within IQVIA .\n",
      "\n",
      "【Real Result】| distributed analytics \n",
      "【Extract Result】| distributed analytics systems data | IQVIA \n",
      "========================================================================================================================\n",
      "Experience in interpreting results from statistical and mathematical models .\n",
      "\n",
      "【Real Result】| statistical and mathematical models \n",
      "【Extract Result】| statistical | mathematical models \n",
      "========================================================================================================================\n",
      "Knowledge in at least one of the following areas : predictive modeling , machine learning , experimentation methodsExperience extracting and manipulating large datasets\n",
      "\n",
      "【Real Result】| predictive modeling | machine learning \n",
      "【Extract Result】| predictive modeling | machine learning | experimentation methodsExperience extracting \n",
      "========================================================================================================================\n",
      "Extensive R and Python / Django experience\n",
      "\n",
      "【Real Result】| R | Python | Django \n",
      "【Extract Result】| R | Python | Django \n",
      "========================================================================================================================\n",
      "We are seeking a senior - level Data Scientist to join our team .\n",
      "\n",
      "【Real Result】| Data Scientist \n",
      "【Extract Result】| Data Scientist \n",
      "========================================================================================================================\n",
      "5 + years of practical experience with a BS or MS or PhD in Mathematics , Economics , Computer Science , Information Management or Statistics\n",
      "\n",
      "【Real Result】| BS | MS | PhD | Mathematics | Economics | Computer Science | Information Management | Statistics \n",
      "【Extract Result】| BS | MS | PhD | Mathematics | Economics | Computer Science | Information Management | Statistics \n",
      "========================================================================================================================\n",
      "Experience conducting original research using data science techniques , including machine learning , deep learning , statistical modeling , and data visualization\n",
      "\n",
      "【Real Result】| original research | data science | machine learning | deep learning | statistical modeling | data visualization \n",
      "【Extract Result】| original research | data science techniques | machine learning | deep learning | statistical modeling | data visualization \n",
      "========================================================================================================================\n",
      "Knowledge of Cloud Computing technologies , particularly in the AWS environment\n",
      "\n",
      "【Real Result】| Cloud Computing technologies | AWS \n",
      "【Extract Result】| Cloud Computing technologies | AWS \n",
      "========================================================================================================================\n",
      "You will employ your mathematical science , computer science , and quantitative analysis skills to ensure solutions to complex data problems and take full advantage of the NSA 's software and hardware capabilities in all areas of our enterprise , including analytic capabilities , research , and foreign intelligence operations .\n",
      "\n",
      "【Real Result】| mathematical science | computer science | quantitative analysis | analytic capabilities | research \n",
      "【Extract Result】| mathematical science | computer science | quantitative analysis | analytic | research \n",
      "========================================================================================================================\n",
      "Strong communication and data presentation skills\n",
      "\n",
      "【Real Result】| data presentation skills \n",
      "【Extract Result】| communication and | data presentation skills \n",
      "========================================================================================================================\n",
      "As an ML Solutions Lab data scientist , you are proficient in designing and developing advanced ML models to solve diverse challenges and opportunities .\n",
      "\n",
      "【Real Result】| ML \n",
      "【Extract Result】| ML data scientist | ML models \n",
      "========================================================================================================================\n",
      "Expert level coding skills ( Python , R , Scala , SQL , etc ) , and experience developing in a Unix environment .\n",
      "\n",
      "【Real Result】| Python | R | Scala | SQL | Unix \n",
      "【Extract Result】| coding skills | Python | R | Scala | SQL | Unix environment \n",
      "========================================================================================================================\n",
      "Analyze data using advanced analytics techniques in support of process improvement efforts using modern analytics frameworks , including – but not limited to – Python , R , Scala , or equivalent ; Spark , Hadoop file system and others .\n",
      "\n",
      "【Real Result】| advanced analytics | Python | R | Scala | Spark | Hadoop \n",
      "【Extract Result】| advanced analytics | analytics frameworks | Python | R | Scala | Spark | Hadoop file system \n",
      "========================================================================================================================\n",
      "Experience visualizing / presenting data for stakeholders using : Periscope , Business Objects , D3 , ggplot , etc .\n",
      "\n",
      "【Real Result】| visualizing / presenting data | Periscope | D3 | ggplot \n",
      "【Extract Result】| visualizing | Periscope | Business Objects | D3 | ggplot \n",
      "========================================================================================================================\n",
      "Our proprietary platform harnesses machine learning algorithms to enable marketing and sales teams to seamlessly coordinate and optimize multichannel engagement with HCPs .\n",
      "\n",
      "【Real Result】| machine learning \n",
      "【Extract Result】machine learning | marketing | optimize \n",
      "========================================================================================================================\n",
      "The Cognitive / Machine Learning Professional 2 work assignments are varied and frequently require interpretation and independent determination of the appropriate courses of action .\n",
      "\n",
      "【Real Result】| Cognitive | Machine Learning \n",
      "【Extract Result】| Cognitive | Machine Learning \n",
      "========================================================================================================================\n",
      "Demonstrated experience with SAS , QlikView , SQL , PL / SQL , MATLAB or similar statistical tools\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| SAS | QlikView | SQL | PL / SQL | MATLAB \n",
      "【Extract Result】| SAS | QlikView | SQL | PL / | SQL | MATLAB | statistical tools \n",
      "========================================================================================================================\n",
      "Software programming proficiency with Java , C , R , Python , and/or MATLAB\n",
      "\n",
      "【Real Result】| Java | C | R | Python | MATLAB \n",
      "【Extract Result】| Software programming | Java | C | R | Python | and/or MATLAB \n",
      "========================================================================================================================\n",
      "We are seeking a Data Scientist to assist in analyzing and implementing data driven solutions to problems specific to risk analysis projects and programs .\n",
      "\n",
      "【Real Result】| Data Scientist | risk analysis \n",
      "【Extract Result】| Data Scientist | analyzing | data \n",
      "========================================================================================================================\n",
      "As this Data Scientist , you will use established programmatic and quantitative methods to find patterns and relationships in large data sets .\n",
      "\n",
      "【Real Result】| quantitative methods | find patterns \n",
      "【Extract Result】| Data Scientist | programmatic quantitative methods \n",
      "========================================================================================================================\n",
      "MS degree in Electrical Engineering , Computer Engineering , or Computer Science ; and at least 6 years of related experience researching and providing data science solutions in the areas of data understanding and insight , big data and cloud computing .\n",
      "\n",
      "【Real Result】| MS degree | Electrical Engineering | Computer Engineering | Computer Science | big data | cloud computing \n",
      "【Extract Result】| Electrical Engineering | Computer Engineering | Computer Science | data science | data | insight | big data | cloud computing \n",
      "========================================================================================================================\n",
      "Excellent communication and presentation skills\n",
      "\n",
      "【Real Result】| communication and presentation skills \n",
      "【Extract Result】| communication and | presentation skills \n",
      "========================================================================================================================\n",
      "Perform rapid ad - hoc analysis and present results in a clear manner starting with structured or unstructured datasets\n",
      "\n",
      "【Real Result】| ad - hoc analysis \n",
      "【Extract Result】- hoc analysis | structured | unstructured datasets \n",
      "========================================================================================================================\n",
      "A Bachelors , Masters or Doctoral degree in Computer Science , Computational Linguistics , Engineering , Statistics , Machine Learning , or Natural Sciences\n",
      "\n",
      "【Real Result】| Bachelors | Masters | Doctoral degree | Computer Science | Computational Linguistics | Engineering | Statistics | Machine Learning | Natural Sciences \n",
      "【Extract Result】| Bachelors | Masters | Doctoral | Computer Science | Computational Linguistics | Engineering | Statistics | Machine Learning | Natural Sciences \n",
      "========================================================================================================================\n",
      "In addition , this role will be responsible for the following : collect , process and cleanse raw data from a wide variety of sources .\n",
      "\n",
      "【Real Result】| collect | process | cleanse \n",
      "【Extract Result】\n",
      "========================================================================================================================\n",
      "Experience with R , Python\n",
      "\n",
      "【Real Result】| R | Python \n",
      "【Extract Result】| R | Python \n",
      "========================================================================================================================\n",
      "Strong experience using machine learning and deep learning packages\n",
      "\n",
      "【Real Result】| machine learning | deep learning \n",
      "【Extract Result】| machine learning | deep learning packages \n",
      "========================================================================================================================\n",
      "7 + year ’s professional experience working in quantitative computational role\n",
      "\n",
      "【Real Result】| quantitative computational \n",
      "【Extract Result】| quantitative | computational role \n",
      "========================================================================================================================\n",
      "Advanced degree in physics , applied mathematics , statistics or related field is preferred\n",
      "\n",
      "【Real Result】| Advanced degree | physics | applied mathematics | statistics \n",
      "【Extract Result】degree | physics | applied mathematics | statistics \n",
      "========================================================================================================================\n",
      "Prepare data for modelling and make best / creative use of applicable and available internal or external data\n",
      "\n",
      "【Real Result】| modelling \n",
      "【Extract Result】modelling \n",
      "========================================================================================================================\n",
      "Strong grounding in machine learning ( ML ) approaches and techniques\n",
      "\n",
      "【Real Result】| machine learning | ML \n",
      "【Extract Result】| machine learning | ML approaches \n",
      "========================================================================================================================\n",
      "Natural language processing\n",
      "\n",
      "【Real Result】| Natural language processing \n",
      "【Extract Result】| language processing \n",
      "========================================================================================================================\n",
      "Strong SQL skills , and experience coding with Python ( or R )\n",
      "\n",
      "【Real Result】| SQL | Python | R \n",
      "【Extract Result】| SQL skills | Python ( | R \n",
      "========================================================================================================================\n",
      "5 + years of experience as a Data Scientist , preferably in Big Data Environment\n",
      "\n",
      "【Real Result】| Data Scientist | Big Data Environment \n",
      "【Extract Result】| Data Scientist | preferably | Big Data Environment \n",
      "========================================================================================================================\n",
      "Experience with the Atlassian suite of tools ( Confluence , JIRA ) and GitLab code repository .\n",
      "\n",
      "【Real Result】| Atlassian suite | Confluence | JIRA | GitLab \n",
      "【Extract Result】| tools | Confluence | JIRA | GitLab \n",
      "========================================================================================================================\n",
      "Supports the generation of an automated insights generation framework for business partners to effectively interpret data Provides actionable insights through data science on Personalization , Search & Navigation , SEO & Promotions , Supply Chain , Services , other company priorities , etc .\n",
      "\n",
      "【Real Result】| Personalization | Search | Navigation | SEO | Promotions | Supply Chain | Services \n",
      "【Extract Result】| data science Personalization | Search & | Navigation | SEO & Promotions | Supply Chain | company priorities \n",
      "========================================================================================================================\n",
      "Should have hands on experience in applying SVM , Neural Nets , Random Forest , K - means clustering , Nearest neighbor , CHAID , CART etc .\n",
      "\n",
      "【Real Result】| SVM | Neural Nets | Random Forest | K - means clustering | Nearest neighbor | CHAID | CART \n",
      "【Extract Result】| SVM | Neural Nets | Random Forest | K - means clustering | neighbor | CHAID | CART \n",
      "========================================================================================================================\n",
      "Experience in Object Oriented Programming ( OOP ) Languages\n",
      "\n",
      "【Real Result】| Object Oriented Programming | OOP \n",
      "【Extract Result】| Object Oriented Programming | OOP \n",
      "========================================================================================================================\n",
      "Expert working within enterprise data warehouse environments platforms ( Teradata , Netezza , Oracle , etc . ) and working within distributed computing platforms such as Hadoop and associated technologies such as SQL , HQL , MapReduce , Spark , Storm , Yarn , Kafka , Sqoop and Hive .\n",
      "\n",
      "【Real Result】| data warehouse | Teradata | Netezza | Oracle | distributed computing platforms | Hadoop | SQL | HQL | MapReduce | Spark | Storm | Yarn | Kafka | Sqoop | Hive \n",
      "【Extract Result】data warehouse environments platforms | Teradata | Netezza | Oracle | distributed computing platforms | Hadoop | SQL | HQL | MapReduce | Spark | Storm | Yarn | Kafka | Sqoop \n",
      "========================================================================================================================\n",
      "Experience with software development , either an open - source enterprise software development stack ( Java / Linux / Ruby / Python ) or a Windows development stack ( .NET , C # , C++ ) .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Real Result】| software development | Java | Linux | Ruby | Python | .NET | C # | C++ \n",
      "【Extract Result】| software development enterprise software development stack | Java | Linux | Ruby / | Python | Windows development stack | .NET | C # | C++ \n",
      "========================================================================================================================\n",
      "Real world experience using Hadoop and the related query engines ( Hive / Impala )\n",
      "\n",
      "【Real Result】| Hadoop | query engines | Hive | Impala \n",
      "【Extract Result】| Hadoop | query engines | Hive / | Impala \n",
      "========================================================================================================================\n",
      "Proficiency in designing & solving classification / prediction problems using open source libraries such as Scikit learn .\n",
      "\n",
      "【Real Result】| classification | prediction | Scikit learn \n",
      "【Extract Result】| designing | classification / | prediction problems | open source | Scikit learn \n",
      "========================================================================================================================\n",
      "Deep understanding of and experience of modern machine learning techniques such as classification , recommendation systems , and other shallow learning techniques , data analytics , and statistical models .\n",
      "\n",
      "【Real Result】| modern machine learning techniques | classification | recommendation systems | data analytics | statistical models \n",
      "【Extract Result】| machine learning techniques | classification | recommendation systems | shallow learning techniques | data analytics | statistical models \n",
      "========================================================================================================================\n",
      "You 'll have an opportunity to interact directly with our Product , Design , and Business leadership teams to surface critical topics , identify innovative practices , and develop high - impact solutions that advance the state - of - the - art in User Experience research .\n",
      "\n",
      "【Real Result】| User Experience research \n",
      "【Extract Result】| Design \n",
      "========================================================================================================================\n",
      "Experience with Apache Spark Natural Language Processing ( tokenization , tagging , sentiment analysis , entity recognition , summarization )\n",
      "\n",
      "【Real Result】| Apache Spark | Natural Language Processing | tokenization | tagging | sentiment analysis | entity recognition | summarization \n",
      "【Extract Result】| Apache Natural Language Processing | tokenization | tagging | sentiment analysis | entity recognition | summarization \n",
      "========================================================================================================================\n",
      "Knowledge of statistics including hypothesis testing\n",
      "\n",
      "【Real Result】| statistics | hypothesis testing \n",
      "【Extract Result】| statistics | hypothesis testing \n",
      "========================================================================================================================\n",
      "problem scoping , data gathering , EDA , modelling , insights , and visualizations\n",
      "\n",
      "【Real Result】| problem scoping | data gathering | EDA | modelling | insights | visualizations \n",
      "【Extract Result】| problem scoping | data gathering | EDA | modelling | insights | visualizations \n",
      "========================================================================================================================\n",
      "Graduate degree in Data Science or Data Analytics or a related quantitative field .\n",
      "\n",
      "【Real Result】| Data Science | Data Analytics | quantitative field \n",
      "【Extract Result】| Data Science | Data Analytics \n",
      "========================================================================================================================\n",
      "Help improve the scope our data sets by identifying new data collection and procurement opportunities on an ongoing basis Drive A / B , multivariate tests and design of experiments to facilitate testing of new product and design features , with a focus on improving engagement , retention , and conversion .\n",
      "\n",
      "【Real Result】| A / B , multivariate tests | design features \n",
      "【Extract Result】collection | multivariate tests | design features | retention \n",
      "========================================================================================================================\n",
      "5 - 7 years of experience in developing and implementing advanced machine learning or algorithmic solutions in a data rich environment .\n",
      "\n",
      "【Real Result】| machine learning | algorithmic | data rich environment \n",
      "【Extract Result】| advanced | machine learning | algorithmic | data \n",
      "========================================================================================================================\n",
      "Exposure to different Machine Learning techniques , and\n",
      "\n",
      "【Real Result】| Machine Learning \n",
      "【Extract Result】| Machine Learning techniques \n",
      "========================================================================================================================\n",
      "Experience in quantitative analysis and translation of findings into actionable insights\n",
      "\n",
      "【Real Result】| quantitative analysis \n",
      "【Extract Result】| quantitative analysis | actionable \n",
      "========================================================================================================================\n",
      "Develop and implement databases , data collection systems , data analytics , and other strategies that will provide efficient data and reporting solutions .\n",
      "\n",
      "【Real Result】| databases | data collection systems | data analytics \n",
      "【Extract Result】| databases | data collection systems | data analytics | data | reporting solutions \n",
      "========================================================================================================================\n",
      "Knowledge of at least one modeling framework ( e.g. , SciKit Learn , TensorFlow , SAS , R , MATLAB )\n",
      "\n",
      "【Real Result】| modeling framework | SciKit Learn | TensorFlow | SAS | R | MATLAB \n",
      "【Extract Result】| modeling framework | e.g. | SciKit Learn | TensorFlow | SAS | R | MATLAB \n",
      "========================================================================================================================\n",
      "Data Science , Math , Statistics or Information Management background\n",
      "\n",
      "【Real Result】| Data Science | Math | Statistics | Information Management \n",
      "【Extract Result】| Data Science | Math | Statistics | Information Management background \n",
      "========================================================================================================================\n",
      "Continually refines and optimizes Machine Learning algorithms .\n",
      "\n",
      "【Real Result】| Machine Learning \n",
      "【Extract Result】| refines | optimizes Machine Learning algorithms \n",
      "========================================================================================================================\n",
      "Data Mining , Machine Learning , Optimization Predictive and Prescriptive Analytics\n",
      "\n",
      "【Real Result】| Data Mining | Machine Learning | Optimization Predictive and Prescriptive Analytics \n",
      "【Extract Result】| Data Mining | Machine Learning | Optimization Predictive | Prescriptive Analytics \n",
      "========================================================================================================================\n",
      "Lead Data Scientist works with business partners around the enterprise to lead the design , development , and implementation of analytics / machine learning solutions that drive measurable business outcomes and create a distinctive customer experience .\n",
      "\n",
      "【Real Result】| design | development | implementation | analytics / machine learning \n",
      "【Extract Result】| Data Scientist | analytics | machine learning \n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "indeX = 0\n",
    "for tem in test_x:\n",
    "    print( ' '.join(tem) )\n",
    "    print()\n",
    "    print( '【Real Result】' ,end='' )\n",
    "    for i in range( len( tem ) ):\n",
    "        if test_y[indeX][i] == 'B':\n",
    "            print( '|',tem[i],'',end='' )\n",
    "            \n",
    "        if test_y[indeX][i] == 'I':\n",
    "            print( tem[i],'',end='' )\n",
    "            \n",
    "    print_predict( model, tem  )\n",
    "    \n",
    "    indeX +=1 \n",
    "    print( '=' * 120 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input a random JD output Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en_core_web_sm'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process( model, tem ):\n",
    "    temp_list = []\n",
    "    predict_list = model.ModelPredict( [w.lower() for w in tem] )\n",
    "            \n",
    "    for index in range(0,len(predict_list)):\n",
    "        if predict_list[index] == 'B' or predict_list[index] == 'I':\n",
    "            temp_list.append(  \"<span style='background:yellow'>\"+str(tem[index])+'</span>' )\n",
    "            \n",
    "        else:\n",
    "            temp_list.append( str(tem[index]) )\n",
    "        \n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Query</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>388</td>\n",
       "      <td>388</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;P&gt;&lt;STRONG&gt;As a member of the Web and Portal D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;BR&gt;\\r&lt;TABLE border=0 cellSpacing=0 cellPaddin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;strong&gt;Application Developer-Senior-Java&lt;br&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4631</td>\n",
       "      <td>4631</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;b&gt;Responsibilities:&lt;/b&gt; Kforce is seeking a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>4873</td>\n",
       "      <td>4873</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>&lt;b&gt;Responsibilities:&lt;/b&gt; Our client is looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71866</th>\n",
       "      <td>1114580</td>\n",
       "      <td>1114580</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Energize Global Services CJSC is looking for J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71871</th>\n",
       "      <td>1114616</td>\n",
       "      <td>1114616</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Workfront is a technology company that needs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71875</th>\n",
       "      <td>1114710</td>\n",
       "      <td>1114710</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>EPAM Systems, Inc. is seeking Java Developers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71889</th>\n",
       "      <td>1114949</td>\n",
       "      <td>1114949</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Monitis is looking for a Java Developer who wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71895</th>\n",
       "      <td>1115103</td>\n",
       "      <td>1115103</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>NASDAQ OMX Armenia is seeking an energetic Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1796 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1           Query  \\\n",
       "6             388           388  Java Developer   \n",
       "7             395           395  Java Developer   \n",
       "11            713           713  Java Developer   \n",
       "118          4631          4631  Java Developer   \n",
       "132          4873          4873  Java Developer   \n",
       "...           ...           ...             ...   \n",
       "71866     1114580       1114580  Java Developer   \n",
       "71871     1114616       1114616  Java Developer   \n",
       "71875     1114710       1114710  Java Developer   \n",
       "71889     1114949       1114949  Java Developer   \n",
       "71895     1115103       1115103  Java Developer   \n",
       "\n",
       "                                             Description  \n",
       "6      <P><STRONG>As a member of the Web and Portal D...  \n",
       "7      <BR>\\r<TABLE border=0 cellSpacing=0 cellPaddin...  \n",
       "11     <strong>Application Developer-Senior-Java<br>\\...  \n",
       "118    <b>Responsibilities:</b> Kforce is seeking a m...  \n",
       "132    <b>Responsibilities:</b> Our client is looking...  \n",
       "...                                                  ...  \n",
       "71866  Energize Global Services CJSC is looking for J...  \n",
       "71871  Workfront is a technology company that needs a...  \n",
       "71875  EPAM Systems, Inc. is seeking Java Developers ...  \n",
       "71889  Monitis is looking for a Java Developer who wi...  \n",
       "71895  NASDAQ OMX Armenia is seeking an energetic Jav...  \n",
       "\n",
       "[1796 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JD_DF = pd.read_csv(r'../Data/JD.csv')\n",
    "JD_DF = JD_DF[JD_DF['Query'] == 'Java Developer']\n",
    "JD_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get a random JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infosys is currently searching for a Java Developer to join their team in Bentonville, AR.  Infosys is the business critical technology partner for the world’s most successful organizations. As a global leader in Business Transformation, Infosys provides strategic business consulting, technology, engineering and outsourcing services to help clients leverage technology and create impactful and measurable business value for every IT investment.  \n",
      "  \n",
      "THIS POSITION IS LOCATED IN BENTONVILLE, AR.  RELOCATION TO BENTONVILLE, AR, IS REQUIRED.  RELOCATION ASSISTANCE IS AVAILABLE FOR QUALIFIED CANDIDATES.\n",
      "  \n",
      "POSITION RESPONSIBILITIES:\n",
      "\n",
      "    Participate in estimation, staffing analysis and solutioning in order to provide inputs for preparing solution delivery for the proposal.\n",
      "    Participate in discussions with customers to gather scope information and perform analysis of scope information in order to provide inputs for project scope documentation\n",
      "    Participate in requirement elicitation process defined in the project management plan to identify requirement gaps/issues (both functional and non-functional) in order to come up with a comprehensive requirement document\n",
      "    Perform high and Low level design , provides pseudo codes, Implements the prototypes and does design reviews in order to deliver design documents as per customer requirements\n",
      "    Mentor the team in Technical Competencies and provides performance feedback of the individual team member to the Project Manager in order to manage performance\n",
      "    Interface with the customer for issue resolution, provide status updates, Build customer confidence in team’s ability to deliver in order to support high customer satisfaction \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = JD_DF.sample(1).iloc[0]['Description']\n",
    "soup = BeautifulSoup(text)\n",
    "text = soup.get_text()\n",
    "\n",
    "for sentence in text.replace('\\\\r','\\\\n').split('\\\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output the NER result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>Infosys is currently searching for a <span style='background:red'>Java</span> <span style='background:red'>Developer</span> to join their team in <span style='background:red'>Bentonville</span> , AR .    Infosys is the business critical technology partner for the world ’s most successful organizations . As a global leader in <span style='background:red'>Business</span> <span style='background:red'>Transformation</span> , Infosys provides strategic <span style='background:red'>business</span> <span style='background:red'>consulting</span> , <span style='background:red'>technology</span> , engineering and outsourcing services to help clients leverage technology and create impactful and measurable business value for every IT investment .    <br>    <br> THIS POSITION IS LOCATED IN <span style='background:red'>BENTONVILLE</span> , AR .    RELOCATION TO BENTONVILLE , AR , IS REQUIRED .    RELOCATION ASSISTANCE IS AVAILABLE FOR QUALIFIED CANDIDATES . <br>    <br> POSITION RESPONSIBILITIES : <span style='background:red'><br></span> <br>      Participate in <span style='background:red'>estimation</span> , <span style='background:red'>staffing</span> <span style='background:red'>analysis</span> and solutioning in order to provide inputs for preparing solution delivery for the proposal . <br>      Participate in discussions with customers to gather scope information and perform analysis of scope information in order to provide inputs for project scope documentation <br>      Participate in requirement elicitation process defined in the project management plan to identify requirement gaps / issues ( both functional and non - functional ) in order to come up with a comprehensive requirement document <span style='background:red'><br></span>      Perform high and Low level <span style='background:red'>design</span> , provides <span style='background:red'>pseudo</span> <span style='background:red'>codes</span> , Implements the prototypes and does design reviews in order to deliver design documents as per <span style='background:red'>customer</span> requirements <br>      Mentor the team in Technical Competencies and provides <span style='background:red'>performance</span> <span style='background:red'>feedback</span> of the individual team member to the Project Manager in order to manage performance <span style='background:red'><br></span>      Interface with the customer for issue resolution , provide status updates , Build customer confidence in team ’s ability to deliver in order to support high customer satisfaction <br> <br></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [sentence for sentence in text.replace('\\\\t',' ').replace('\\\\r','\\\\n').split('\\\\n')]\n",
    "\n",
    "total_text_list = []\n",
    "for sent in sentences:\n",
    "#     sentence = str(sent).replace('\\r',' ').replace('\\\\r',' ').replace('\\\\n',' ').replace('\\n',' ').replace('\\t',' ').replace('\\\\t',' ')\n",
    "#     sentence = sentence.strip(' ')\n",
    "    \n",
    "    total_text_list += process( model, [str(w) for w in list(nlp(sent))[:120] ] +['<br>'] )\n",
    "#     print( '-' * 120 )\n",
    "\n",
    "display(HTML( '<html>'+' '.join(total_text_list) + '</html>' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU_py36",
   "language": "python",
   "name": "tf_gpu_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
